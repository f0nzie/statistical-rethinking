<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10 Counting and Classification | Statistical Rethinking with brms, ggplot2, and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="10 Counting and Classification | Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKURZ/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10 Counting and Classification | Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-07-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="big-entropy-and-the-generalized-linear-model.html">
<link rel="next" href="monsters-and-mixtures.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>This is a love letter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this"><i class="fa fa-check"></i>Why this?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#my-assumptions-about-you"><i class="fa fa-check"></i>My assumptions about you</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-and-understand-this-project"><i class="fa fa-check"></i>How to use and understand this project</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-do-this-too"><i class="fa fa-check"></i>You can do this, too</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#we-have-updates"><i class="fa fa-check"></i>We have updates</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#reference"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#using-prior-information."><i class="fa fa-check"></i><b>2.1.2</b> Using prior information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#likelihood."><i class="fa fa-check"></i><b>2.3.1</b> Likelihood.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#parameters."><i class="fa fa-check"></i><b>2.3.2</b> Parameters.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#prior."><i class="fa fa-check"></i><b>2.3.3</b> Prior.</a></li>
<li class="chapter" data-level="2.3.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#posterior."><i class="fa fa-check"></i><b>2.3.4</b> Posterior.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.1</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.2</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.3</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#reference-1"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-like-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-like approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-in-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice in brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#reference-2"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-models.html"><a href="linear-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-models.html"><a href="linear-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-models.html"><a href="linear-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-models.html"><a href="linear-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-models.html"><a href="linear-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-models.html"><a href="linear-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-models.html"><a href="linear-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-models.html"><a href="linear-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-models.html"><a href="linear-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-models.html"><a href="linear-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-models.html"><a href="linear-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-models.html"><a href="linear-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model-with-map-brm."><i class="fa fa-check"></i><b>4.3.5</b> Fitting the model with <del><code>map()</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-models.html"><a href="linear-models.html#sampling-from-a-map-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>map()</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-models.html"><a href="linear-models.html#adding-a-predictor"><i class="fa fa-check"></i><b>4.4</b> Adding a predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-models.html"><a href="linear-models.html#the-linear-model-strategy"><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model."><i class="fa fa-check"></i><b>4.4.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-models.html"><a href="linear-models.html#interpreting-the-model-fit."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the model fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-models.html"><a href="linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>4.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#reference-3"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html"><i class="fa fa-check"></i><b>5</b> Multivariate Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multivariate-notation."><i class="fa fa-check"></i><b>5.1.1</b> Multivariate notation.</a></li>
<li class="chapter" data-level="5.1.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#fitting-the-model.-1"><i class="fa fa-check"></i><b>5.1.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="5.1.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.3</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinearity"><i class="fa fa-check"></i><b>5.3</b> Multicollinearity</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-legs."><i class="fa fa-check"></i><b>5.3.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="5.3.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-milk."><i class="fa fa-check"></i><b>5.3.2</b> Multicollinear <code>milk</code>.</a></li>
<li class="chapter" data-level="5.3.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#post-treatment-bias."><i class="fa fa-check"></i><b>5.3.3</b> Post-treatment bias.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#categorical-varaibles"><i class="fa fa-check"></i><b>5.4</b> Categorical varaibles</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#binary-categories."><i class="fa fa-check"></i><b>5.4.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#many-categories."><i class="fa fa-check"></i><b>5.4.2</b> Many categories.</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#adding-regular-predictor-variables."><i class="fa fa-check"></i><b>5.4.3</b> Adding regular predictor variables.</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#another-approach-unique-intercepts."><i class="fa fa-check"></i><b>5.4.4</b> Another approach: Unique intercepts.</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#ordinary-least-squares-and-lm"><i class="fa fa-check"></i><b>5.5</b> <del>Ordinary least squares and <code>lm()</code></del></a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#reference-4"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html"><i class="fa fa-check"></i><b>6</b> Overfitting, Regularization, and Information Criteria</a><ul>
<li class="chapter" data-level="6.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>6.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="6.1.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#more-parameters-always-improve-fit."><i class="fa fa-check"></i><b>6.1.1</b> More parameters always improve fit.</a></li>
<li class="chapter" data-level="6.1.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>6.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-theory-and-model-performance"><i class="fa fa-check"></i><b>6.2</b> Information theory and model performance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>6.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="6.2.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty."><i class="fa fa-check"></i><b>6.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="6.2.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>6.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="6.2.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-divergence-to-deviance."><i class="fa fa-check"></i><b>6.2.4</b> From divergence to deviance.</a></li>
<li class="chapter" data-level="6.2.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-deviance-to-out-of-sample."><i class="fa fa-check"></i><b>6.2.5</b> From deviance to out-of-sample.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#regularization"><i class="fa fa-check"></i><b>6.3</b> Regularization</a></li>
<li class="chapter" data-level="6.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-criteria"><i class="fa fa-check"></i><b>6.4</b> Information criteria</a><ul>
<li class="chapter" data-level="6.4.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic."><i class="fa fa-check"></i><b>6.4.1</b> DIC.</a></li>
<li class="chapter" data-level="6.4.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#waic."><i class="fa fa-check"></i><b>6.4.2</b> WAIC.</a></li>
<li class="chapter" data-level="6.4.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic-and-waic-as-estimates-of-deviance."><i class="fa fa-check"></i><b>6.4.3</b> DIC and WAIC as estimates of deviance.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#using-information-criteria"><i class="fa fa-check"></i><b>6.5</b> Using information criteria</a><ul>
<li class="chapter" data-level="6.5.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-comparison."><i class="fa fa-check"></i><b>6.5.1</b> Model comparison.</a></li>
<li class="chapter" data-level="6.5.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-averaging."><i class="fa fa-check"></i><b>6.5.2</b> Model averaging.</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>6.6</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#reference-5"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>7</b> Interactions</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#building-an-interaction."><i class="fa fa-check"></i><b>7.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="7.1.1" data-path="interactions.html"><a href="interactions.html#adding-a-dummy-variable-doesnt-work."><i class="fa fa-check"></i><b>7.1.1</b> Adding a dummy variable doesn’t work.</a></li>
<li class="chapter" data-level="7.1.2" data-path="interactions.html"><a href="interactions.html#adding-a-linear-interaction-does-work."><i class="fa fa-check"></i><b>7.1.2</b> Adding a linear interaction does work.</a></li>
<li class="chapter" data-level="7.1.3" data-path="interactions.html"><a href="interactions.html#plotting-the-interaction."><i class="fa fa-check"></i><b>7.1.3</b> Plotting the interaction.</a></li>
<li class="chapter" data-level="7.1.4" data-path="interactions.html"><a href="interactions.html#interpreting-an-interaction-estimate."><i class="fa fa-check"></i><b>7.1.4</b> Interpreting an interaction estimate.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="interactions.html"><a href="interactions.html#symmetry-of-the-linear-interaction."><i class="fa fa-check"></i><b>7.2</b> Symmetry of the linear interaction.</a><ul>
<li class="chapter" data-level="7.2.1" data-path="interactions.html"><a href="interactions.html#buridans-interaction."><i class="fa fa-check"></i><b>7.2.1</b> Buridan’s interaction.</a></li>
<li class="chapter" data-level="7.2.2" data-path="interactions.html"><a href="interactions.html#africa-depends-upon-ruggedness."><i class="fa fa-check"></i><b>7.2.2</b> Africa depends upon ruggedness.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interactions.html"><a href="interactions.html#continuous-interactions"><i class="fa fa-check"></i><b>7.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interactions.html"><a href="interactions.html#the-data.-1"><i class="fa fa-check"></i><b>7.3.1</b> The data.</a></li>
<li class="chapter" data-level="7.3.2" data-path="interactions.html"><a href="interactions.html#the-un-centered-models."><i class="fa fa-check"></i><b>7.3.2</b> The un-centered models.</a></li>
<li class="chapter" data-level="7.3.3" data-path="interactions.html"><a href="interactions.html#center-and-re-estimate."><i class="fa fa-check"></i><b>7.3.3</b> Center and re-estimate.</a></li>
<li class="chapter" data-level="7.3.4" data-path="interactions.html"><a href="interactions.html#plotting-implied-predictions."><i class="fa fa-check"></i><b>7.3.4</b> Plotting implied predictions.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="interactions.html"><a href="interactions.html#interactions-in-design-formulas"><i class="fa fa-check"></i><b>7.4</b> Interactions in design formulas</a></li>
<li class="chapter" data-level="7.5" data-path="interactions.html"><a href="interactions.html#summary-bonus-marginal_effects"><i class="fa fa-check"></i><b>7.5</b> <del>Summary</del> Bonus: <code>marginal_effects()</code></a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#reference-6"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>8</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>8.1</b> Good King Markov and His island kingdom</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-1"><i class="fa fa-check"></i><b>8.2</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm"><i class="fa fa-check"></i><b>8.3</b> Easy HMC: <del>map2stan</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="8.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>8.3.1</b> Preparation.</a></li>
<li class="chapter" data-level="8.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#estimation."><i class="fa fa-check"></i><b>8.3.2</b> Estimation.</a></li>
<li class="chapter" data-level="8.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>8.3.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="8.3.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>8.3.4</b> Visualization.</a></li>
<li class="chapter" data-level="8.3.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#using-the-samples."><i class="fa fa-check"></i><b>8.3.5</b> Using the samples.</a></li>
<li class="chapter" data-level="8.3.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>8.3.6</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>8.4</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="8.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>8.4.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="8.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>8.4.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="8.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>8.4.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="8.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>8.4.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#reference-7"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>9</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="9.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>9.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="9.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>9.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>9.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>9.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>9.2.2</b> Linking linear models to distributions.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#reference-8"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="counting-and-classification.html"><a href="counting-and-classification.html"><i class="fa fa-check"></i><b>10</b> Counting and Classification</a><ul>
<li class="chapter" data-level="10.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#binomial-regression"><i class="fa fa-check"></i><b>10.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>10.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="10.1.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>10.1.2</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="10.1.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>10.1.3</b> Aggregated binomial: Graduate school admissions.</a></li>
<li class="chapter" data-level="10.1.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#fitting-binomial-regressions-with-glm."><i class="fa fa-check"></i><b>10.1.4</b> Fitting binomial regressions with <code>glm()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>10.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="10.2.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#mcmc-islands."><i class="fa fa-check"></i><b>10.2.2</b> MCMC islands.</a></li>
<li class="chapter" data-level="10.2.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>10.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#other-count-regressions"><i class="fa fa-check"></i><b>10.3</b> Other count regressions</a><ul>
<li class="chapter" data-level="10.3.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#multinomial."><i class="fa fa-check"></i><b>10.3.1</b> Multinomial.</a></li>
<li class="chapter" data-level="10.3.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#geometric."><i class="fa fa-check"></i><b>10.3.2</b> Geometric.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#reference-9"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>11</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="11.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>11.1</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>11.1.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="11.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>11.1.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="11.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>11.1.3</b> Adding predictor variables.</a></li>
<li class="chapter" data-level="11.1.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#bonus-figure-11.3-alternative."><i class="fa fa-check"></i><b>11.1.4</b> Bonus: Figure 11.3 alternative.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>11.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>11.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-outcomes"><i class="fa fa-check"></i><b>11.3</b> Over-dispersed outcomes</a><ul>
<li class="chapter" data-level="11.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>11.3.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="11.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>11.3.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="11.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>11.3.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#reference-10"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>12.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>12.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#the-model.-1"><i class="fa fa-check"></i><b>12.2.1</b> The model.</a></li>
<li class="chapter" data-level="12.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>12.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="12.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#sumulate-survivors."><i class="fa fa-check"></i><b>12.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="12.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>12.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="12.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>12.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>12.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="12.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>12.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="12.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#two-types-of-cluster."><i class="fa fa-check"></i><b>12.3.2</b> Two types of cluster.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>12.4</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>12.4.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="12.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>12.4.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="12.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#focus-and-multilevel-prediction."><i class="fa fa-check"></i><b>12.4.3</b> Focus and multilevel prediction.</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="multilevel-models.html"><a href="multilevel-models.html#summary-bonus-tidybayesspread_draws"><i class="fa fa-check"></i><b>12.5</b> <del>Summary</del> Bonus: <code>tidybayes::spread_draws()</code></a><ul>
<li class="chapter" data-level="12.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#intercepts-only-models-with-one-or-two-grouping-variables"><i class="fa fa-check"></i><b>12.5.1</b> Intercepts-only models with one or two grouping variables</a></li>
<li class="chapter" data-level="12.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsposterior_samples"><i class="fa fa-check"></i><b>12.5.2</b> <code>brms::posterior_samples()</code></a></li>
<li class="chapter" data-level="12.5.3" data-path="multilevel-models.html"><a href="multilevel-models.html#brmscoef"><i class="fa fa-check"></i><b>12.5.3</b> <code>brms::coef()</code></a></li>
<li class="chapter" data-level="12.5.4" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsfitted"><i class="fa fa-check"></i><b>12.5.4</b> <code>brms::fitted()</code></a></li>
<li class="chapter" data-level="12.5.5" data-path="multilevel-models.html"><a href="multilevel-models.html#tidybayesspread_draws"><i class="fa fa-check"></i><b>12.5.5</b> <code>tidybayes::spread_draws()</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#reference-11"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>13</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>13.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>13.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="13.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>13.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="13.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>13.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-admission-decisions-and-gender"><i class="fa fa-check"></i><b>13.2</b> Example: Admission decisions and gender</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-intercepts."><i class="fa fa-check"></i><b>13.2.1</b> Varying intercepts.</a></li>
<li class="chapter" data-level="13.2.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-effects-of-being-male."><i class="fa fa-check"></i><b>13.2.2</b> Varying effects of being <code>male</code>.</a></li>
<li class="chapter" data-level="13.2.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#shrinkage."><i class="fa fa-check"></i><b>13.2.3</b> Shrinkage.</a></li>
<li class="chapter" data-level="13.2.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#model-comparison.-1"><i class="fa fa-check"></i><b>13.2.4</b> Model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-cross-classified-chimpanzees-with-varying-slopes"><i class="fa fa-check"></i><b>13.3</b> Example: Cross-classified <code>chimpanzees</code> with varying slopes</a></li>
<li class="chapter" data-level="13.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>13.4</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="13.4.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>13.4.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-another-berkley-admissions-data-like-example."><i class="fa fa-check"></i><b>13.5</b> <del>Summary</del> Bonus: Another Berkley-admissions-data-like example.</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#reference-12"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>14</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="14.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>14.1</b> Measurement error</a><ul>
<li class="chapter" data-level="14.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>14.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="14.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>14.1.2</b> Error on both outcome and predictor.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>14.2</b> Missing data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-neocortex"><i class="fa fa-check"></i><b>14.2.1</b> Imputing <code>neocortex</code></a></li>
<li class="chapter" data-level="14.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#improving-the-imputation-model"><i class="fa fa-check"></i><b>14.2.2</b> Improving the imputation model</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#summary-bonus-meta-analysis"><i class="fa fa-check"></i><b>14.3</b> <del>Summary</del> Bonus: Meta-analysis</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#reference-13"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>15</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="15.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>15.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="15.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>15.2</b> Save your model fits</a></li>
<li class="chapter" data-level="15.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>15.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="15.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>15.4</b> Look at your data</a></li>
<li class="chapter" data-level="15.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-the-0-intercept-syntax"><i class="fa fa-check"></i><b>15.5</b> Use the <code>0 + intercept</code> syntax</a></li>
<li class="chapter" data-level="15.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>15.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="15.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>15.7</b> Annotate your code</a></li>
<li class="chapter" data-level="15.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>15.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="15.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#read-gelmans-blog"><i class="fa fa-check"></i><b>15.9</b> Read Gelman’s blog</a></li>
<li class="chapter" data-level="15.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-other-social-media-too"><i class="fa fa-check"></i><b>15.10</b> Check out other social media, too</a></li>
<li class="chapter" data-level="15.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>15.11</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#reference-14"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical Rethinking</em> with brms, ggplot2, and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="counting-and-classification" class="section level1">
<h1><span class="header-section-number">10</span> Counting and Classification</h1>
<blockquote>
<p>All over the world, every day, scientists throw away information. Sometimes this is through the removal of “outliers,” cases in the data that offend the model and are exiled. More routinely, counted things are converted to proportions before analysis. Why does analysis of proportions throw away information? Because 10/20 and ½ are the same proportion, one-half, but have very different sample sizes. Once converted to proportions, and treated as outcomes in a linear regression, the information about sample size has been destroyed.</p>
<p>It’s easy to retain the information about sample size. All that is needed is to model what has actually been observed, the counts instead of the proportions. (p. 291)</p>
</blockquote>
<p>In this chapter, we focus on the two most common types of count models: the binomial and the Poisson.</p>
<p>Side note: For a nice Bayesian way to accommodate outliers in your Gaussian models, check out my blog <a href="https://solomonkurz.netlify.com/post/robust-linear-regression-with-the-robust-student-s-t-distribution/"><em>Robust Linear Regression with Student’s <span class="math inline">\(t\)</span>-Distribution</em></a>.</p>
<div id="binomial-regression" class="section level2">
<h2><span class="header-section-number">10.1</span> Binomial regression</h2>
<p>The basic binomial model follows the form</p>
<p><span class="math display">\[y \sim \text{Binomial} (n, p)\]</span></p>
<p>where <span class="math inline">\(y\)</span> is some count variable, <span class="math inline">\(n\)</span> is the number of trials, and <span class="math inline">\(p\)</span> it the probability a given trial was a 1, which is sometimes termed a <em>success</em>. When <span class="math inline">\(n = 1\)</span>, then <span class="math inline">\(y\)</span> is a vector of 0s and 1s. Presuming the logit link, models of this type are commonly termed logistic regression. When <span class="math inline">\(n &gt; 1\)</span>, and still presuming the logit link, we might call our model an aggregated logistic regression model, or more generally an aggregated binomial regression model.</p>
<div id="logistic-regression-prosocial-chimpanzees." class="section level3">
<h3><span class="header-section-number">10.1.1</span> Logistic regression: Prosocial chimpanzees.</h3>
<p>Load the <code>chimpanzees</code> data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(chimpanzees)
d &lt;-<span class="st"> </span>chimpanzees</code></pre>
<p>Switch from rethinking to brms.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)
<span class="kw">rm</span>(chimpanzees)</code></pre>
<p>We start with the simple intercept-only logistic regression model, which follows the statistical formula</p>
<p><span class="math display">\[\begin{align*}
\text{pulled_left}_i &amp; \sim \text{Binomial} (1, p_i) \\
\text{logit} (p_i)    &amp; = \alpha \\
\alpha                &amp; \sim \text{Normal} (0, 10)
\end{align*}\]</span></p>
<p>In the <code>brm()</code> <code>formula</code> syntax, including a <code>|</code> bar on the left side of a formula indicates we have extra supplementary information about our criterion. In this case, that information is that each <code>pulled_left</code> value corresponds to a single trial (i.e., <code>trials(1)</code>), which itself corresponds to the <span class="math inline">\(n = 1\)</span> portion of the statistical formula, above.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.1</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      pulled_left <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(<span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>You might use <code>fixef()</code> to get a focused summary of the intercept.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
 
<span class="kw">fixef</span>(b10<span class="fl">.1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##           Estimate Est.Error Q2.5 Q97.5
## Intercept     0.32      0.09 0.14   0.5</code></pre>
<p>The <code>brms::inv_logit_scaled()</code> function will be our alternative to the <code>logistic()</code> function in rethinking.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">c</span>(.<span class="dv">18</span>, <span class="fl">.46</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inv_logit_scaled</span>()</code></pre>
<pre><code>## [1] 0.5448789 0.6130142</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inv_logit_scaled</span>()</code></pre>
<pre><code>##           Estimate Est.Error      Q2.5     Q97.5
## Intercept 0.578806 0.5231408 0.5349467 0.6229265</code></pre>
<p>With the next two chimp models, we add predictors in the usual way.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.2</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      pulled_left <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(<span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>prosoc_left,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b)),
      <span class="dt">seed =</span> <span class="dv">10</span>)

b10<span class="fl">.3</span> &lt;-
<span class="st">  </span><span class="kw">update</span>(b10<span class="fl">.2</span>,
         <span class="dt">newdata =</span> d,
         <span class="dt">formula =</span> pulled_left <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(<span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>prosoc_left <span class="op">+</span><span class="st"> </span>condition<span class="op">:</span>prosoc_left)</code></pre>
<p>Compute the WAIC for each model and save the results within the brmfit objects.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.1</span>, <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.2</span>, <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.3</span>, <span class="st">&quot;waic&quot;</span>)</code></pre>
<p>Compare them with the <code>loo_compare()</code> and make sure to add the <code>criterion = &quot;waic&quot;</code> argument.</p>
<pre class="sourceCode r"><code class="sourceCode r">w &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(b10<span class="fl">.1</span>, b10<span class="fl">.2</span>, b10<span class="fl">.3</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)

<span class="kw">print</span>(w, <span class="dt">simplify =</span> F)</code></pre>
<pre><code>##       elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic   se_waic
## b10.2    0.0       0.0  -340.3       4.7          2.1    0.0     680.6    9.4 
## b10.3   -1.0       0.4  -341.3       4.7          3.1    0.1     682.6    9.5 
## b10.1   -3.7       3.1  -344.0       3.5          1.1    0.0     688.1    7.1</code></pre>
<p>Recall our <code>cbind()</code> trick to convert the differences from the <span class="math inline">\(\text{elpd}\)</span> metric to the WAIC metric.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cbind</span>(<span class="dt">waic_diff =</span> w[, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="dv">-2</span>,
      <span class="dt">se        =</span> w[, <span class="dv">2</span>] <span class="op">*</span><span class="st">  </span><span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##       waic_diff   se
## b10.2      0.00 0.00
## b10.3      1.98 0.81
## b10.1      7.42 6.21</code></pre>
<p>For this chapter, we’ll take our color scheme from the <a href="https://cran.r-project.org/web/packages/wesanderson/index.html">wesanderson package</a>’s <code>Moonrise2</code> palette.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;wesanderson&quot;, dependencies = T)</span>
<span class="kw">library</span>(wesanderson)

<span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-8-1.png" width="288" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]</code></pre>
<pre><code>## [1] &quot;#798E87&quot; &quot;#C27D38&quot; &quot;#CCC591&quot; &quot;#29211F&quot;</code></pre>
<p>We’ll also take a few formatting cues from <a href="https://www.edwardtufte.com/tufte/books_vdqi">Edward Tufte</a>, curtesy of the <a href="https://cran.r-project.org/web/packages/ggthemes/index.html">ggthemes package</a>. The <code>theme_tufte()</code> function will change the default font and remove some chart junk. The <code>theme_set()</code> function, below, will make these adjustments the default for all subsequent ggplot2 plots. To undo this, just execute <code>theme_set(theme_default())</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggthemes)
<span class="kw">library</span>(bayesplot)

<span class="kw">theme_set</span>(<span class="kw">theme_default</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">            </span><span class="kw">theme_tufte</span>() <span class="op">+</span>
<span class="st">            </span><span class="kw">theme</span>(<span class="dt">plot.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill  =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">3</span>],
                                                 <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">3</span>])))</code></pre>
<p>Finally, here’s our WAIC plot.</p>
<pre class="sourceCode r"><code class="sourceCode r">w <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="dt">var =</span> <span class="st">&quot;model&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">reorder</span>(model, <span class="op">-</span>waic), <span class="dt">y =</span> waic,
                      <span class="dt">ymin =</span> waic <span class="op">-</span><span class="st"> </span>se_waic,
                      <span class="dt">ymax =</span> waic <span class="op">+</span><span class="st"> </span>se_waic,
                      <span class="dt">color =</span> model),
                  <span class="dt">shape =</span> <span class="dv">16</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dv">4</span>)]) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>,
       <span class="dt">title =</span> <span class="st">&quot;WAIC&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y    =</span> <span class="kw">element_blank</span>(),
        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-10-1.png" width="432" /></p>
<p>The full model, <code>b10.3</code>, did not have the lowest WAIC value. Though note how wide those standard error bars are relative to the point estimates. There’s a lot of model uncertainty there. Here are the WAIC weights.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model_weights</span>(b10<span class="fl">.1</span>, b10<span class="fl">.2</span>, b10<span class="fl">.3</span>, 
              <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>)</code></pre>
<pre><code>##      b10.1      b10.2      b10.3 
## 0.01752164 0.71641630 0.26606206</code></pre>
<p>Let’s look at the parameter summaries for the theory-based model.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.3</span>)</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: pulled_left | trials(1) ~ prosoc_left + prosoc_left:condition 
##    Data: d (Number of observations: 504) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept                 0.05      0.13    -0.21     0.31       3031 1.00
## prosoc_left               0.61      0.23     0.17     1.05       2607 1.00
## prosoc_left:condition    -0.10      0.27    -0.63     0.43       2575 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here’s what the odds are multiplied by:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.3</span>)[<span class="dv">2</span>] <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">exp</span>()</code></pre>
<pre><code>## [1] 1.847029</code></pre>
<p>Given an estimated value of 4, the probability of a pull, all else equal, would be close to 1.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inv_logit_scaled</span>(<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.9820138</code></pre>
<p>Adding the coefficient, <code>fixef(b10.3)[2]</code>, would yield an even higher estimate.</p>
<pre class="sourceCode r"><code class="sourceCode r">(<span class="dv">4</span> <span class="op">+</span><span class="st"> </span><span class="kw">fixef</span>(b10<span class="fl">.3</span>)[<span class="dv">2</span>]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inv_logit_scaled</span>()</code></pre>
<pre><code>## [1] 0.9901811</code></pre>
<p>For our variant of Figure 10.2, we use <code>brms::pp_average()</code> in place of <code>rethinking::ensemble()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the combined `fitted()` results of the three models weighted by their WAICs</span>
ppa &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">pp_average</span>(b10<span class="fl">.1</span>, b10<span class="fl">.2</span>, b10<span class="fl">.3</span>,
             <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>,
             <span class="dt">method =</span> <span class="st">&quot;fitted&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(b10<span class="fl">.3</span><span class="op">$</span>data) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(Estimate, Q2<span class="fl">.5</span>, Q97<span class="fl">.5</span>, condition, prosoc_left) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x_axis =</span> <span class="kw">str_c</span>(prosoc_left, condition, <span class="dt">sep =</span> <span class="st">&quot;/&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x_axis =</span> <span class="kw">factor</span>(x_axis, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">pulled_left =</span> Estimate)

<span class="co"># the empirically-based summaries</span>
d_plot &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(actor, condition, prosoc_left) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">pulled_left =</span> <span class="kw">mean</span>(pulled_left)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x_axis =</span> <span class="kw">str_c</span>(prosoc_left, condition, <span class="dt">sep =</span> <span class="st">&quot;/&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x_axis =</span> <span class="kw">factor</span>(x_axis, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))

<span class="co"># the plot</span>
ppa <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x_axis)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">y =</span> pulled_left, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>, <span class="dt">group =</span> <span class="dv">0</span>),
              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,
              <span class="dt">fill =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, 
              <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> d_plot,
            <span class="kw">aes</span>(<span class="dt">y =</span> pulled_left, <span class="dt">group =</span> actor),
            <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">expand =</span> <span class="kw">c</span>(.<span class="dv">03</span>, <span class="fl">.03</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;prosoc_left/condition&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;proportion pulled left&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>())</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-15-1.png" width="288" /></p>
<p>McElreath didn’t show the actual pairs plot in the text. Here’s ours using <code>mcmc_pairs()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># this helps us set our custom color scheme</span>
<span class="kw">color_scheme_set</span>(<span class="kw">c</span>(<span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">3</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>]))

<span class="co"># the actual plot</span>
<span class="kw">mcmc_pairs</span>(<span class="dt">x =</span> <span class="kw">posterior_samples</span>(b10<span class="fl">.3</span>),
           <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>, <span class="st">&quot;b_prosoc_left&quot;</span>, <span class="st">&quot;b_prosoc_left:condition&quot;</span>),
           <span class="dt">off_diag_args =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),
           <span class="dt">diag_fun =</span> <span class="st">&quot;dens&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-16-1.png" width="432" /></p>
<p>As McElreath observed, the posterior looks multivariate Gaussian.</p>
<p>In equations, the next model follows the form</p>
<p><span class="math display">\[\begin{align*}
\text{pulled_left}_i &amp; \sim \text{Binomial} (1, p_i) \\
\text{logit} (p_i)    &amp; = \alpha_{\text{actor}} + (\beta_1 + \beta_2 \text{condition}_i) \text{prosoc_left}_i \\
\alpha_{\text{actor}} &amp; \sim \text{Normal} (0, 10) \\
\beta_1               &amp; \sim \text{Normal} (0, 10) \\
\beta_2               &amp; \sim \text{Normal} (0, 10)
\end{align*}\]</span></p>
<p>Enclosing the <code>actor</code> variable within <code>factor()</code> will produce the indexing we need to get <code>actor</code>-specific intercepts. Also notice we’re using the <code>0 + factor(actor)</code> part of the model <code>formula</code> to suppress the brms default intercept. As such, the priors for all parameters in the model will be of <code>class = b</code>. And since we’re using the same Gaussian prior for each, we only need one line for the <code>prior</code> argument.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.4</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      pulled_left <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(<span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(actor) <span class="op">+</span><span class="st"> </span>prosoc_left <span class="op">+</span><span class="st"> </span>condition<span class="op">:</span>prosoc_left ,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">cores =</span> <span class="dv">2</span>,
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.9</span>),
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>Within the tidyverse, <code>distinct()</code> yields the information you’d otherwise get from <code>unique()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">distinct</span>(actor)</code></pre>
<pre><code>##   actor
## 1     1
## 2     2
## 3     3
## 4     4
## 5     5
## 6     6
## 7     7</code></pre>
<p>We have no need to use something like <code>depth=2</code> for our posterior summary.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.4</span>)</code></pre>
<pre><code>## Warning: There were 2 divergent transitions after warmup. Increasing adapt_delta above 0.9 may help.
## See http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: pulled_left | trials(1) ~ 0 + factor(actor) + prosoc_left + condition:prosoc_left 
##    Data: d (Number of observations: 504) 
## Samples: 2 chains, each with iter = 2500; warmup = 500; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## factoractor1             -0.74      0.27    -1.28    -0.21       3322 1.00
## factoractor2             10.69      5.27     4.07    23.93       1589 1.00
## factoractor3             -1.06      0.28    -1.60    -0.51       3587 1.00
## factoractor4             -1.05      0.28    -1.64    -0.51       3340 1.00
## factoractor5             -0.74      0.27    -1.29    -0.23       3683 1.00
## factoractor6              0.22      0.27    -0.30     0.74       3578 1.00
## factoractor7              1.81      0.40     1.08     2.63       3724 1.00
## prosoc_left               0.83      0.26     0.33     1.35       2283 1.00
## prosoc_left:condition    -0.13      0.30    -0.72     0.44       3284 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Correspondingly, <code>brms::posterior_samples()</code> returns an object for <code>b10.4</code> that doesn’t quite follow the same structure as from <code>rethinking::extract.samples()</code>. We just have a typical 2-dimensional data frame.</p>
<pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b10<span class="fl">.4</span>)
 
post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre>
<pre><code>## Observations: 4,000
## Variables: 10
## $ b_factoractor1            &lt;dbl&gt; -0.6249345, -0.7478057, -0.7415190, -0.7592423, -0.9709409, -0.6540401, -…
## $ b_factoractor2            &lt;dbl&gt; 13.383148, 7.497157, 6.433093, 6.500553, 6.823564, 5.992749, 8.000636, 10…
## $ b_factoractor3            &lt;dbl&gt; -0.6887826, -1.4565022, -1.3877612, -1.5074418, -1.4247839, -0.9429962, -…
## $ b_factoractor4            &lt;dbl&gt; -0.7747454, -1.2061288, -1.1664359, -1.1308661, -1.0699072, -1.1439220, -…
## $ b_factoractor5            &lt;dbl&gt; -0.1975562, -1.2977602, -1.3162522, -1.2186394, -0.9225723, -0.7272301, -…
## $ b_factoractor6            &lt;dbl&gt; -0.17577770, 0.68844247, 0.76287267, 0.88287084, 0.63865462, -0.39060396,…
## $ b_factoractor7            &lt;dbl&gt; 1.425294, 2.094121, 2.194396, 1.638241, 1.425664, 1.973291, 1.567078, 1.9…
## $ b_prosoc_left             &lt;dbl&gt; 0.4627765, 0.8767337, 0.8756102, 1.1859353, 1.0564925, 0.9258368, 0.54429…
## $ `b_prosoc_left:condition` &lt;dbl&gt; -0.033540094, -0.152316937, -0.215346334, -0.107831118, -0.244684340, -0.…
## $ lp__                      &lt;dbl&gt; -292.2600, -291.9762, -292.6513, -293.7977, -289.3733, -289.3551, -287.26…</code></pre>
<p>Our variant of Figure 10.3:</p>
<pre class="sourceCode r"><code class="sourceCode r">post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> b_factoractor2)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>,
               <span class="dt">fill =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x        =</span> <span class="ot">NULL</span>,
       <span class="dt">title    =</span> <span class="st">&quot;Actor 2&#39;s large and uncertain intercept&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Once your log-odds are above, like, 4, it&#39;s all</span><span class="ch">\n</span><span class="st">pretty much a probability of 1.&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-20-1.png" width="288" /></p>
<p>Figure 10.4. shows the idiographic trajectories for four of our chimps.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># subset the `d_plot` data</span>
d_plot_<span class="dv">4</span> &lt;-
<span class="st">  </span>d_plot <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(actor <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span><span class="op">:</span><span class="dv">7</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">actor =</span> <span class="kw">str_c</span>(<span class="st">&quot;actor &quot;</span>, actor))

<span class="co"># compute the model-implied estimates with `fitted()` and wrangle</span>
f &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b10<span class="fl">.4</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(b10<span class="fl">.4</span><span class="op">$</span>data) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(actor <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span><span class="op">:</span><span class="dv">7</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(Estimate, Q2<span class="fl">.5</span>, Q97<span class="fl">.5</span>, condition, prosoc_left, actor) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(actor, <span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">actor  =</span> <span class="kw">str_c</span>(<span class="st">&quot;actor &quot;</span>, actor),
         <span class="dt">x_axis =</span> <span class="kw">str_c</span>(prosoc_left, condition, <span class="dt">sep =</span> <span class="st">&quot;/&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x_axis =</span> <span class="kw">factor</span>(x_axis, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">pulled_left =</span> Estimate)

<span class="co"># plot</span>
f <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x_axis, <span class="dt">y =</span> pulled_left, <span class="dt">group =</span> actor)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),
              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,
              <span class="dt">fill =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, 
              <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> d_plot_<span class="dv">4</span>,
            <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], <span class="dt">size =</span> <span class="fl">1.25</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="dt">expand =</span> <span class="kw">c</span>(.<span class="dv">03</span>, <span class="fl">.03</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;prosoc_left/condition&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;proportion pulled left&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x     =</span> <span class="kw">element_blank</span>(),
        <span class="co"># color came from: http://www.color-hex.com/color/ccc591</span>
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;#d1ca9c&quot;</span>,
                                        <span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>actor)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-21-1.png" width="576" /></p>
<div id="overthinking-using-the-by-group_by-function." class="section level4">
<h4><span class="header-section-number">10.1.1.1</span> Overthinking: Using the <del>by</del> <code>group_by()</code> function.</h4>
<p>Let’s work within the tidyverse, instead. If you wanted to compute the proportion of trials <code>pulled_left == 1</code> for each combination of <code>prosoc_left</code>, <code>condition</code>, and chimp <code>actor</code>, you’d put those last three variables within <code>group_by()</code> and then compute the <code>mean()</code> of <code>pulled_left</code> within <code>summarise()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(prosoc_left, condition, actor) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="st">`</span><span class="dt">proportion pulled_left</span><span class="st">`</span> =<span class="st"> </span><span class="kw">mean</span>(pulled_left))</code></pre>
<pre><code>## # A tibble: 28 x 4
## # Groups:   prosoc_left, condition [4]
##    prosoc_left condition actor `proportion pulled_left`
##          &lt;int&gt;     &lt;int&gt; &lt;int&gt;                    &lt;dbl&gt;
##  1           0         0     1                    0.333
##  2           0         0     2                    1    
##  3           0         0     3                    0.278
##  4           0         0     4                    0.333
##  5           0         0     5                    0.333
##  6           0         0     6                    0.778
##  7           0         0     7                    0.778
##  8           0         1     1                    0.278
##  9           0         1     2                    1    
## 10           0         1     3                    0.167
## # … with 18 more rows</code></pre>
<p>And since we’re working within the tidyverse, that operation returns a tibble rather than a list.</p>
</div>
</div>
<div id="aggregated-binomial-chimpanzees-again-condensed." class="section level3">
<h3><span class="header-section-number">10.1.2</span> Aggregated binomial: Chimpanzees again, condensed.</h3>
<p>With the tidyverse, we use <code>group_by()</code> and <code>summarise()</code> to achieve what McElreath did with <code>aggregate()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d_aggregated &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>recipient, <span class="op">-</span>block, <span class="op">-</span>trial, <span class="op">-</span>chose_prosoc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(actor, condition, prosoc_left) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">x =</span> <span class="kw">sum</span>(pulled_left))

d_aggregated <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(actor <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</code></pre>
<pre><code>## # A tibble: 8 x 4
## # Groups:   actor, condition [4]
##   actor condition prosoc_left     x
##   &lt;int&gt;     &lt;int&gt;       &lt;int&gt; &lt;int&gt;
## 1     1         0           0     6
## 2     1         0           1     9
## 3     1         1           0     5
## 4     1         1           1    10
## 5     2         0           0    18
## 6     2         0           1    18
## 7     2         1           0    18
## 8     2         1           1    18</code></pre>
<p>To fit an aggregated binomial model in brms, we augment the <code>&lt;criterion&gt; | trials()</code> syntax where the value that goes in <code>trials()</code> is either a fixed number, as in this case, or variable in the data indexing <span class="math inline">\(n\)</span>. Either way, at least some of those trials will have an <span class="math inline">\(n &gt; 1\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.5</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d_aggregated, <span class="dt">family =</span> binomial,
      x <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(<span class="dv">18</span>) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>prosoc_left <span class="op">+</span><span class="st"> </span>condition<span class="op">:</span>prosoc_left,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>, 
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>We might compare <code>b10.3</code> with <code>b10.5</code> like this.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.3</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##                       Estimate Est.Error  Q2.5 Q97.5
## Intercept                 0.05      0.13 -0.21  0.31
## prosoc_left               0.61      0.23  0.17  1.05
## prosoc_left:condition    -0.10      0.27 -0.63  0.43</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.5</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##                       Estimate Est.Error  Q2.5 Q97.5
## Intercept                 0.05      0.13 -0.20  0.31
## prosoc_left               0.60      0.23  0.14  1.07
## prosoc_left:condition    -0.09      0.27 -0.60  0.46</code></pre>
<p>A coefficient plot can offer a complimentary perspective.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(broom)

<span class="co"># wrangle</span>
<span class="kw">tibble</span>(<span class="dt">model  =</span> <span class="kw">str_c</span>(<span class="st">&quot;b10.&quot;</span>, <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">fit  =</span> <span class="kw">map</span>(model, get)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">tidy =</span> <span class="kw">map</span>(fit, tidy)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(tidy) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;lp__&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># plot</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="kw">aes</span>(<span class="dt">x =</span> model, <span class="dt">y =</span> estimate,
                      <span class="dt">ymin =</span> lower,
                      <span class="dt">ymax =</span> upper,
                      <span class="dt">color =</span> term),
                  <span class="dt">shape =</span> <span class="dv">16</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dv">4</span>)]) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y    =</span> <span class="kw">element_blank</span>(),
        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>term, <span class="dt">ncol =</span> <span class="dv">1</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-25-1.png" width="432" /></p>
<p>The two are close within simulation error.</p>
</div>
<div id="aggregated-binomial-graduate-school-admissions." class="section level3">
<h3><span class="header-section-number">10.1.3</span> Aggregated binomial: Graduate school admissions.</h3>
<p>Load the infamous <code>UCBadmit</code> data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># detach(package:brms)</span>
<span class="kw">library</span>(rethinking)
<span class="kw">data</span>(UCBadmit)
d &lt;-<span class="st"> </span>UCBadmit</code></pre>
<p>Switch from rethinking to brms.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)
<span class="kw">rm</span>(UCBadmit)

d</code></pre>
<pre><code>##    dept applicant.gender admit reject applications
## 1     A             male   512    313          825
## 2     A           female    89     19          108
## 3     B             male   353    207          560
## 4     B           female    17      8           25
## 5     C             male   120    205          325
## 6     C           female   202    391          593
## 7     D             male   138    279          417
## 8     D           female   131    244          375
## 9     E             male    53    138          191
## 10    E           female    94    299          393
## 11    F             male    22    351          373
## 12    F           female    24    317          341</code></pre>
<p>Now compute our newly-constructed dummy variable, <code>male</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d &lt;-<span class="st"> </span>
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">male =</span> <span class="kw">ifelse</span>(applicant.gender <span class="op">==</span><span class="st"> &quot;male&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</code></pre>
<p>The univariable logistic model with <code>male</code> as the sole predictor of <code>admit</code> follows the form</p>
<p><span class="math display">\[\begin{align*}
n_{\text{admit}_i} &amp; \sim \text{Binomial} (n_i, p_i) \\
\text{logit} (p_i) &amp; = \alpha + \beta \text{male}_i \\
\alpha             &amp; \sim \text{Normal} (0, 10) \\
\beta              &amp; \sim \text{Normal} (0, 10)
\end{align*}\]</span></p>
<p>The second model omits the <code>male</code> predictor.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.6</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      admit <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(applications) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>male ,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>) 

b10<span class="fl">.7</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      admit <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(applications) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>Compute the information criteria for each model and save the results within the brmfit objects.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.6</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.6</span>, <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.7</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.7</span>, <span class="st">&quot;waic&quot;</span>)</code></pre>
<p>Here’s the WAIC comparison.</p>
<pre class="sourceCode r"><code class="sourceCode r">w &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(b10<span class="fl">.6</span>, b10<span class="fl">.7</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)

<span class="kw">print</span>(w, <span class="dt">simplify =</span> F)</code></pre>
<pre><code>##       elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic   se_waic
## b10.6    0.0       0.0  -498.0     164.3        116.4   41.7     996.0  328.5 
## b10.7  -28.6      82.6  -526.6     165.2         88.1   38.4    1053.2  330.4</code></pre>
<p>If you prefer the difference in the WAIC metric, use our <code>cbind()</code> conversion method from above.</p>
<p><strong>Bonus: Information criteria digression.</strong></p>
<p>Let’s see what happens if we switch to the LOO.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.6</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.6</span>, <span class="st">&quot;loo&quot;</span>)</code></pre>
<pre><code>## Warning: Found 7 observations with a pareto_k &gt; 0.7 in model &#39;b10.6&#39;. It is recommended to set &#39;reloo = TRUE&#39;
## in order to calculate the ELPD without the assumption that these observations are negligible. This will refit
## the model 7 times to compute the ELPDs for the problematic observations directly.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.7</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.7</span>, <span class="st">&quot;loo&quot;</span>)</code></pre>
<pre><code>## Warning: Found 5 observations with a pareto_k &gt; 0.7 in model &#39;b10.7&#39;. It is recommended to set &#39;reloo = TRUE&#39;
## in order to calculate the ELPD without the assumption that these observations are negligible. This will refit
## the model 5 times to compute the ELPDs for the problematic observations directly.</code></pre>
<p>If you just ape the text and use the WAIC, everything appears fine. But holy smokes look at those nasty warning messages from the <code>loo()</code>! One of the frightening but ultimately handy things about working with the PSIS-LOO is that it requires we estimate a Pareto <span class="math inline">\(k\)</span> parameter, which you can learn all about in the <code>loo-package</code> section of the <a href="https://cran.r-project.org/web/packages/loo/loo.pdf">loo reference manual</a>. As it turns out, the Pareto <span class="math inline">\(k\)</span> <a href="https://cran.r-project.org/web/packages/loo/vignettes/loo2-example.html#plotting-pareto-k-diagnostics">can be used as a diagnostic tool</a>. Each case in the data gets its own <span class="math inline">\(k\)</span> value and we like it when those <span class="math inline">\(k\)</span>s are low. The makers of the loo package get worried when those <span class="math inline">\(k\)</span>s exceed 0.7 and as a result, <code>loo()</code> spits out a warning message when they do.</p>
<p>First things first, if you explicitly open the loo package, you’ll have access to some handy diagnostic functions.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(loo)</code></pre>
<p>We’ll be leveraging those <span class="math inline">\(k\)</span> values with the <code>pareto_k_table()</code> and <code>pareto_k_ids()</code> functions. Both functions take objects created by the <code>loo()</code> or <code>psis()</code> functions. So, before we can get busy, we’ll first make two objects with the <code>loo()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.6</span> &lt;-<span class="st"> </span><span class="kw">loo</span>(b10<span class="fl">.6</span>)</code></pre>
<pre><code>## Warning: Found 7 observations with a pareto_k &gt; 0.7 in model &#39;b10.6&#39;. It is recommended to set &#39;reloo = TRUE&#39;
## in order to calculate the ELPD without the assumption that these observations are negligible. This will refit
## the model 7 times to compute the ELPDs for the problematic observations directly.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.7</span> &lt;-<span class="st"> </span><span class="kw">loo</span>(b10<span class="fl">.7</span>)</code></pre>
<pre><code>## Warning: Found 5 observations with a pareto_k &gt; 0.7 in model &#39;b10.7&#39;. It is recommended to set &#39;reloo = TRUE&#39;
## in order to calculate the ELPD without the assumption that these observations are negligible. This will refit
## the model 5 times to compute the ELPDs for the problematic observations directly.</code></pre>
<p>There are those warning messages, again. Using the loo-object for model <code>b10.6</code>, which we’ve named <code>l_b10.6</code>, let’s take a look at the <code>pareto_k_table()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pareto_k_table</span>(l_b10<span class="fl">.6</span>) </code></pre>
<pre><code>## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     4     33.3%   462       
##  (0.5, 0.7]   (ok)       1      8.3%   132       
##    (0.7, 1]   (bad)      2     16.7%   68        
##    (1, Inf)   (very bad) 5     41.7%   2</code></pre>
<p>You may have noticed that this same table pops out when you just do something like <code>loo(b10.6)</code>. Recall that this data set has 12 observations (i.e., execute <code>count(d)</code>). With <code>pareto_k_table()</code>, we see how the Pareto <span class="math inline">\(k\)</span> values have been categorized into bins ranging from “good” to “very bad”. Clearly, we like nice and low <span class="math inline">\(k\)</span>s. In this example, our observations are all over the place, with 5 in the “bad” <span class="math inline">\(k\)</span> range We can take a closer look like this:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(l_b10<span class="fl">.6</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-35-1.png" width="432" /></p>
<p>So when you <code>plot()</code> a loo object, you get a nice diagnostic plot for those <span class="math inline">\(k\)</span> values, ordered by observation number. Our plot indicates cases 1, 2, 3, 11, and 12 had “very bad” <span class="math inline">\(k\)</span> values for this model. If we wanted to further verify to ourselves which observations those were, we’d use the <code>pareto_k_ids()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pareto_k_ids</span>(l_b10<span class="fl">.6</span>, <span class="dt">threshold =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## [1]  1  2  3 11 12</code></pre>
<p>Note our use of the <code>threshold</code> argument. Play around with it to see how it works.</p>
<p>If you want an explicit look at those <span class="math inline">\(k\)</span> values, you do:</p>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.6</span><span class="op">$</span>diagnostics</code></pre>
<pre><code>## $pareto_k
##  [1] 2.67957810 1.11451857 1.88623531 0.09922047 0.39156088 0.68199122 0.72578896 0.47271647 0.43565612
## [10] 0.71024673 1.95868789 1.78759806
## 
## $n_eff
##  [1]    2.342374   13.293075    3.608359 1867.198063  839.806222  131.652439   68.013983  548.286594
##  [9]  461.687490  154.225368    2.546589    6.994980</code></pre>
<p>The <code>pareto_k</code> values can be used to examine cases that are overly-influential on the model parameters, something like a Cook’s <span class="math inline">\(D_{i}\)</span>. See, for example <a href="https://stackoverflow.com/questions/39578834/linear-model-diagnostics-for-bayesian-models-using-rstan/39595436">this discussion on stackoverflow.com</a> in which several members of the <a href="http://mc-stan.org">Stan team</a> weighed in. The issue is also discussed in <a href="https://arxiv.org/abs/1507.04544">this paper</a> and in <a href="https://www.youtube.com/watch?v=FUROJM3u5HQ&amp;feature=youtu.be&amp;a=">this presentation by Aki Vehtari</a>.</p>
<p>Anyway, the implication of all this is these values suggest model <code>b10.6</code> isn’t a great fit for these data.</p>
<p>Part of the warning message for model <code>b10.6</code> read:</p>
<blockquote>
<p>It is recommended to set ‘reloo = TRUE’ in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model [<span class="math inline">\(n\)</span>] times to compute the ELPDs for the problematic observations directly.</p>
</blockquote>
<p>Let’s do that.</p>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.6</span>_reloo &lt;-<span class="st"> </span><span class="kw">loo</span>(b10<span class="fl">.6</span>, <span class="dt">reloo =</span> T)</code></pre>
<p>Check the results.</p>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.6</span>_reloo</code></pre>
<pre><code>## 
## Computed from 4000 by 12 log-likelihood matrix
## 
##          Estimate    SE
## elpd_loo   -512.1 167.1
## p_loo       130.6  48.3
## looic      1024.2 334.2
## ------
## Monte Carlo SE of elpd_loo is NA.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     11    91.7%   2         
##  (0.5, 0.7]   (ok)        1     8.3%   132       
##    (0.7, 1]   (bad)       0     0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>Now that looks better. We’ll do the same thing for model <code>b10.7</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.7</span>_reloo &lt;-<span class="st"> </span><span class="kw">loo</span>(b10<span class="fl">.7</span>, <span class="dt">reloo =</span> T)</code></pre>
<p>Okay, let’s compare models with formal <span class="math inline">\(\text{elpd}_{\text{loo}}\)</span> differences before and after adjusting with <code>reloo = T</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loo_compare</span>(l_b10<span class="fl">.6</span>, l_b10<span class="fl">.7</span>)</code></pre>
<pre><code>##       elpd_diff se_diff
## b10.6   0.0       0.0  
## b10.7 -29.5      77.8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loo_compare</span>(l_b10<span class="fl">.6</span>_reloo, l_b10<span class="fl">.7</span>_reloo)</code></pre>
<pre><code>##       elpd_diff se_diff
## b10.6   0.0       0.0  
## b10.7 -20.1      79.3</code></pre>
<p>In this case, the results are kinda similar. The standard errors for the differences are huge compared to the point estimates, suggesting large uncertainty. Watch out for this in your real-world data.</p>
<p>But this has all been a tangent from the central thrust of this section.</p>
<p><strong>Back from our information criteria digression.</strong></p>
<p>Let’s get back on track with the text. Here’s a look at <code>b10.6</code>, the unavailable model:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.6</span>)</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: admit | trials(applications) ~ 1 + male 
##    Data: d (Number of observations: 12) 
## Samples: 2 chains, each with iter = 2500; warmup = 500; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept    -0.83      0.05    -0.93    -0.73       2522 1.00
## male          0.61      0.06     0.48     0.74       3059 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here’s the relative difference in admission odds.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.6</span>)[<span class="dv">2</span>] <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">exp</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## [1] 1.84</code></pre>
<p>And now we’ll compute difference in admission probabilities.</p>
<pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b10<span class="fl">.6</span>)

post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_admit_male   =</span> <span class="kw">inv_logit_scaled</span>(b_Intercept <span class="op">+</span><span class="st"> </span>b_male),
         <span class="dt">p_admit_female =</span> <span class="kw">inv_logit_scaled</span>(b_Intercept),
         <span class="dt">diff_admit     =</span> p_admit_male <span class="op">-</span><span class="st"> </span>p_admit_female) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="st">`</span><span class="dt">2.5%</span><span class="st">`</span>  =<span class="st"> </span><span class="kw">quantile</span>(diff_admit, <span class="dt">probs =</span> <span class="fl">.025</span>),
            <span class="st">`</span><span class="dt">50%</span><span class="st">`</span>   =<span class="st"> </span><span class="kw">median</span>(diff_admit),
            <span class="st">`</span><span class="dt">97.5%</span><span class="st">`</span> =<span class="st"> </span><span class="kw">quantile</span>(diff_admit, <span class="dt">probs =</span> <span class="fl">.975</span>))</code></pre>
<pre><code>##        2.5%       50%     97.5%
## 1 0.1139081 0.1415119 0.1699301</code></pre>
<p>Instead of the <code>summarise()</code> code, we could have also used <code>tidybayes::median_qi(diff_admit)</code>. It’s good to have options. Here’s our version of Figure 10.5.</p>
<pre class="sourceCode r"><code class="sourceCode r">d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">case =</span> <span class="kw">factor</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>))

p &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">predict</span>(b10<span class="fl">.6</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(d)

d_text &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(dept) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">case  =</span> <span class="kw">mean</span>(<span class="kw">as.numeric</span>(case)),
            <span class="dt">admit =</span> <span class="kw">mean</span>(admit <span class="op">/</span><span class="st"> </span>applications) <span class="op">+</span><span class="st"> </span><span class="fl">.05</span>)

<span class="kw">ggplot</span>(<span class="dt">data =</span> d, <span class="kw">aes</span>(<span class="dt">x =</span> case, <span class="dt">y =</span> admit <span class="op">/</span><span class="st"> </span>applications)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">data =</span> p, 
                  <span class="kw">aes</span>(<span class="dt">y    =</span> Estimate <span class="op">/</span><span class="st"> </span>applications,
                      <span class="dt">ymin =</span> Q2<span class="fl">.5</span>     <span class="op">/</span><span class="st"> </span>applications ,
                      <span class="dt">ymax =</span> Q97<span class="fl">.5</span>    <span class="op">/</span><span class="st"> </span>applications),
                  <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>],
                  <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> dept),
            <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> d_text,
            <span class="kw">aes</span>(<span class="dt">y =</span> admit, <span class="dt">label =</span> dept),
            <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>],
            <span class="dt">family =</span> <span class="st">&quot;serif&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y     =</span> <span class="st">&quot;Proportion admitted&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Posterior validation check&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>())</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-43-1.png" width="384" /></p>
<p>As alluded to in all that LOO/<code>pareto_k</code> talk, above, this is not a great fit. So we’ll ditch the last model paradigm for one that answers the new question “<em>What is the average difference in probability of admission between females and males within departments?</em>” (p. 307). The statistical formula for the full model follows the form</p>
<p><span class="math display">\[\begin{align*}
n_{\text{admit}_i}   &amp; \sim \text{Binomial} (n_i, p_i) \\
\text{logit} (p_i)   &amp; = \alpha_{\text{dept}_i} + \beta \text{male}_i \\
\alpha_{\text{dept}} &amp; \sim \text{Normal} (0, 10) \\
\beta                &amp; \sim \text{Normal} (0, 10)
\end{align*}\]</span></p>
<p>We don’t need to coerce an index like McElreath did in the text. But here are the models.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.8</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      admit <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(applications) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>dept,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>) 

b10<span class="fl">.9</span> &lt;-
<span class="st">  </span><span class="kw">update</span>(b10<span class="fl">.8</span>,
         <span class="dt">newdata =</span> d,
         <span class="dt">formula =</span> admit <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(applications) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>dept <span class="op">+</span><span class="st"> </span>male)</code></pre>
<p>Let’s make two more <code>loo()</code> objects using <code>reloo = T</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">l_b10<span class="fl">.8</span>_reloo &lt;-<span class="st"> </span><span class="kw">loo</span>(b10<span class="fl">.8</span>, <span class="dt">reloo =</span> T)
l_b10<span class="fl">.9</span>_reloo &lt;-<span class="st"> </span><span class="kw">loo</span>(b10<span class="fl">.9</span>, <span class="dt">reloo =</span> T)</code></pre>
<p>Now compare them.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loo_compare</span>(l_b10<span class="fl">.6</span>_reloo, l_b10<span class="fl">.7</span>_reloo, l_b10<span class="fl">.8</span>_reloo, l_b10<span class="fl">.9</span>_reloo)</code></pre>
<pre><code>##       elpd_diff se_diff
## b10.8    0.0       0.0 
## b10.9   -5.3       2.6 
## b10.6 -446.1     162.7 
## b10.7 -466.2     160.7</code></pre>
<p>Here are the LOO weights.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model_weights</span>(b10<span class="fl">.6</span>, b10<span class="fl">.7</span>, b10<span class="fl">.8</span>, b10<span class="fl">.9</span>,
              <span class="dt">weights =</span> <span class="st">&quot;loo&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">3</span>)</code></pre>
<pre><code>## b10.6 b10.7 b10.8 b10.9 
## 0.000 0.000 0.928 0.072</code></pre>
<p>The parameters summaries for our multivariable model, <code>b10.9</code>, look like this:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.9</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##       Estimate Est.Error  Q2.5 Q97.5
## deptA     0.68      0.10  0.50  0.88
## deptB     0.64      0.12  0.41  0.86
## deptC    -0.58      0.07 -0.73 -0.44
## deptD    -0.62      0.09 -0.78 -0.45
## deptE    -1.06      0.10 -1.27 -0.86
## deptF    -2.64      0.16 -2.96 -2.34
## male     -0.10      0.08 -0.26  0.06</code></pre>
<p>And on the proportional odds scale, the posterior mean for <code>b_male</code> is:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b10<span class="fl">.9</span>)[<span class="dv">7</span>, <span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">exp</span>()</code></pre>
<pre><code>## [1] 0.9066073</code></pre>
<p>Since we’ve been using brms, there’s no need to fit our version of McElreath’s <code>m10.9stan</code>. We already have that in our <code>b10.9</code>. But just for kicks and giggles, here’s another way to get the model summary.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.9</span><span class="op">$</span>fit</code></pre>
<pre><code>## Inference for Stan model: 11ff351173d29f96c679ef5534162471.
## 2 chains, each with iter=2500; warmup=500; thin=1; 
## post-warmup draws per chain=2000, total post-warmup draws=4000.
## 
##           mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## b_deptA   0.68    0.00 0.10   0.50   0.62   0.68   0.75   0.88  1602    1
## b_deptB   0.64    0.00 0.12   0.41   0.56   0.64   0.72   0.86  1681    1
## b_deptC  -0.58    0.00 0.07  -0.73  -0.63  -0.58  -0.53  -0.44  3444    1
## b_deptD  -0.62    0.00 0.09  -0.78  -0.67  -0.61  -0.56  -0.45  2299    1
## b_deptE  -1.06    0.00 0.10  -1.27  -1.13  -1.06  -0.99  -0.86  3622    1
## b_deptF  -2.64    0.00 0.16  -2.96  -2.75  -2.64  -2.53  -2.34  3138    1
## b_male   -0.10    0.00 0.08  -0.26  -0.15  -0.10  -0.04   0.06  1274    1
## lp__    -70.70    0.04 1.89 -75.22 -71.71 -70.39 -69.33 -68.00  1922    1
## 
## Samples were drawn using NUTS(diag_e) at Sun Jul 12 15:49:48 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>Here’s our version of Figure 10.6, the posterior validation check.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(b10<span class="fl">.9</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(d) <span class="op">%&gt;%</span><span class="st"> </span>

<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> case, <span class="dt">y =</span> admit <span class="op">/</span><span class="st"> </span>applications)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="kw">aes</span>(<span class="dt">y    =</span> Estimate <span class="op">/</span><span class="st"> </span>applications,
                      <span class="dt">ymin =</span> Q2<span class="fl">.5</span>     <span class="op">/</span><span class="st"> </span>applications ,
                      <span class="dt">ymax =</span> Q97<span class="fl">.5</span>    <span class="op">/</span><span class="st"> </span>applications),
                  <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>],
                  <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> dept),
            <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> d_text,
            <span class="kw">aes</span>(<span class="dt">y =</span> admit, <span class="dt">label =</span> dept),
            <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>],
            <span class="dt">family =</span> <span class="st">&quot;serif&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y     =</span> <span class="st">&quot;Proportion admitted&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Posterior validation check&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>())</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-49-1.png" width="384" /></p>
<p>The model precisions are imperfect, but way more valid than before. The posterior looks reasonably multivariate Gaussian.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(b10<span class="fl">.9</span>,
      <span class="dt">off_diag_args =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>))</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-50-1.png" width="720" /></p>
<div id="overthinking-waic-and-aggregated-binomial-models." class="section level4">
<h4><span class="header-section-number">10.1.3.1</span> Overthinking: WAIC and aggregated binomial models.</h4>
<p>McElreath wrote:</p>
<blockquote>
<p>The <code>WAIC</code> function in <code>rethinking</code> detects aggregated binomial models and automatically splits them apart into 0/1 Bernoulli trials, for the purpose of calculating WAIC. It does this, because WAIC is computed point by point (see Chapter 6). So what you define as a “point” affects WAIC’s value. In an aggregated binomial each “point” is a bunch of independent trials that happen to share the same predictor values. In order for the disaggregated and aggregated models to agree, it makes sense to use the disaggregated representation. (p. 309)</p>
</blockquote>
<p>To my knowledge, <code>brms::waic()</code> and <code>brms::loo()</code> do not do this, which might well be why some of our values didn’t match up with those in the text. If you have additional insight on this, please <a href="https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/issues">share with the rest of the class</a>.</p>
</div>
</div>
<div id="fitting-binomial-regressions-with-glm." class="section level3">
<h3><span class="header-section-number">10.1.4</span> Fitting binomial regressions with <code>glm()</code>.</h3>
<p>We’re not here to learn frequentist code, so we’re going to skip most of this section. But model <code>b.good</code> is worth fitting. Here are the data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># outcome and predictor almost perfectly associated</span>
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>))
x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">9</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">11</span>))</code></pre>
<p>Fit the <code>b.good</code> model.</p>
<pre class="sourceCode r"><code class="sourceCode r">b.good &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> y, <span class="dt">x =</span> x), <span class="dt">family =</span> binomial,
      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b)),
      <span class="dt">seed =</span> <span class="dv">10</span>) </code></pre>
<p>Our model summary will differ a bit from the one in the text. It seems this is because of the MAP/HMC contrast and our choice of priors.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b.good)</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: y ~ 1 + x 
##    Data: list(y = y, x = x) (Number of observations: 20) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept    -5.22      4.18   -15.39     0.40        563 1.01
## x             7.98      4.17     2.36    18.03        567 1.01
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>You might experiment with different prior <span class="math inline">\(SD\)</span>s to see how they influence the posterior <span class="math inline">\(SD\)</span>s. Anyways, here’s the <code>pairs()</code> plot McElreath excluded from the text.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(b.good,
      <span class="dt">off_diag_args =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>))</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-53-1.png" width="312" /></p>
<p>That posterior, my friends, is not multivariate Gaussian. The plot deserves and extensive quote from McElreath.</p>
<blockquote>
<p>Inspecting the pairs plot (<del>not</del> shown) demonstrates just how subtle even simple models can be, once we start working with GLMs. I don’t say this to scare the reader. But it’s true that even simple models can behave in complicated ways. How you fit the model is part of the model, and in principle no GLM is safe for MAP estimation. (p. 311)</p>
</blockquote>
</div>
</div>
<div id="poisson-regression" class="section level2">
<h2><span class="header-section-number">10.2</span> Poisson regression</h2>
<p>We’ll simulate our sweet count data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">10</span>) <span class="co"># make the results reproducible</span>

<span class="kw">tibble</span>(<span class="dt">y =</span> <span class="kw">rbinom</span>(<span class="fl">1e5</span>, <span class="dv">1000</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">y_mean     =</span> <span class="kw">mean</span>(y),
            <span class="dt">y_variance =</span> <span class="kw">var</span>(y))</code></pre>
<pre><code>## # A tibble: 1 x 2
##   y_mean y_variance
##    &lt;dbl&gt;      &lt;dbl&gt;
## 1  0.994      0.995</code></pre>
<p>Yes, those statistics are virtually the same. When dealing with Poisson data, <span class="math inline">\(\mu = \sigma^2\)</span>. When you have a number of trials for which <span class="math inline">\(n\)</span> is unknown or much larger than seen in the data, the Poisson likelihood is a useful tool. We define it like this</p>
<p><span class="math display">\[y \sim \text{Poisson} (\lambda)\]</span></p>
<p>As <span class="math inline">\(\lambda\)</span> expresses both mean and variance because, within this model, the variance scales right along with the mean. Since <span class="math inline">\(\lambda\)</span> is constrained to be positive, we typically use the log link. Thus the basic Poisson regression model is</p>
<p><span class="math display">\[\begin{align*}
y_i                    &amp; \sim \text{Poisson} (\lambda_i) \\
\text{log} (\lambda_i) &amp; = \alpha + \beta x_i
\end{align*}\]</span></p>
<div id="example-oceanic-tool-complexity." class="section level3">
<h3><span class="header-section-number">10.2.1</span> Example: Oceanic tool complexity.</h3>
<p>Load the <code>Kline</code> data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(Kline)
d &lt;-<span class="st"> </span>Kline</code></pre>
<p>Switch from rethinking to brms.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)
<span class="kw">rm</span>(Kline)

d</code></pre>
<pre><code>##       culture population contact total_tools mean_TU
## 1    Malekula       1100     low          13     3.2
## 2     Tikopia       1500     low          22     4.7
## 3  Santa Cruz       3600     low          24     4.0
## 4         Yap       4791    high          43     5.0
## 5    Lau Fiji       7400    high          33     5.0
## 6   Trobriand       8000    high          19     4.0
## 7       Chuuk       9200    high          40     3.8
## 8       Manus      13000     low          28     6.6
## 9       Tonga      17500    high          55     5.4
## 10     Hawaii     275000     low          71     6.6</code></pre>
<p>Here are our new columns.</p>
<pre class="sourceCode r"><code class="sourceCode r">d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_pop      =</span> <span class="kw">log</span>(population),
         <span class="dt">contact_high =</span> <span class="kw">ifelse</span>(contact <span class="op">==</span><span class="st"> &quot;high&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</code></pre>
<p>Our statistical model will follow the form</p>
<p><span class="math display">\[\begin{align*}
\text{total_tools}_i   &amp; \sim \text{Poisson} (\lambda_i) \\
\text{log} (\lambda_i) &amp; = \alpha + \beta_1 \text{log_pop}_i + \beta_2 \text{contact_high}_i + \beta_3 \text{contact_high}_i \times \text{log_pop}_i \\
\alpha  &amp; \sim \text{Normal} (0, 100) \\
\beta_1 &amp; \sim \text{Normal} (0, 1) \\
\beta_2 &amp; \sim \text{Normal} (0, 1) \\
\beta_3 &amp; \sim \text{Normal} (0, 1)
\end{align*}\]</span></p>
<p>The only new thing in our model code is <code>family = poisson</code>. brms defaults to the <code>log()</code> link.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.10</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> poisson,
      total_tools <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>log_pop <span class="op">+</span><span class="st"> </span>contact_high <span class="op">+</span><span class="st"> </span>contact_high<span class="op">:</span>log_pop,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>) </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.10</span>)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: total_tools ~ 1 + log_pop + contact_high + contact_high:log_pop 
##    Data: d (Number of observations: 10) 
## Samples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##                      Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept                0.94      0.37     0.20     1.64       4075 1.00
## log_pop                  0.26      0.04     0.19     0.33       4317 1.00
## contact_high            -0.09      0.82    -1.70     1.49       2406 1.00
## log_pop:contact_high     0.04      0.09    -0.13     0.22       2397 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here’s the lower triangle of the correlation matrix for the parameters.</p>
<pre class="sourceCode r"><code class="sourceCode r">post &lt;-
<span class="st">  </span><span class="kw">posterior_samples</span>(b10<span class="fl">.10</span>)

post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>lp__) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">b_interaction =</span> <span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>psych<span class="op">::</span><span class="kw">lowerCor</span>()</code></pre>
<pre><code>##                b_Int b_lg_ b_cn_ b_ntr
## b_Intercept     1.00                  
## b_log_pop      -0.98  1.00            
## b_contact_high -0.16  0.16  1.00      
## b_interaction   0.10 -0.12 -0.99  1.00</code></pre>
<p>And here’s the coefficient plot via <code>bayesplot::mcmc_intervals()</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># we&#39;ll set a renewed color theme</span>
<span class="kw">color_scheme_set</span>(<span class="kw">c</span>(<span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>],
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">4</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>]))

post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>lp__) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">b_interaction =</span> <span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="kw">mcmc_intervals</span>(<span class="dt">prob =</span> <span class="fl">.5</span>, <span class="dt">prob_outer =</span> <span class="fl">.95</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-60-1.png" width="768" /></p>
<p>How plausible is it a high-contact island will have more tools than a low-contact island?</p>
<pre class="sourceCode r"><code class="sourceCode r">post &lt;-
<span class="st">  </span>post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">lambda_high =</span> <span class="kw">exp</span>(b_Intercept <span class="op">+</span><span class="st"> </span>b_contact_high <span class="op">+</span><span class="st"> </span>(b_log_pop <span class="op">+</span><span class="st"> `</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>) <span class="op">*</span><span class="st"> </span><span class="dv">8</span>),
         <span class="dt">lambda_low  =</span> <span class="kw">exp</span>(b_Intercept <span class="op">+</span><span class="st"> </span>b_log_pop <span class="op">*</span><span class="st"> </span><span class="dv">8</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">diff        =</span> lambda_high <span class="op">-</span><span class="st"> </span>lambda_low) 

post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">sum =</span> <span class="kw">sum</span>(diff <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(diff))</code></pre>
<pre><code>##      sum
## 1 0.9585</code></pre>
<p>Quite, it turns out. Behold the corresponding Figure 10.8.a.</p>
<pre class="sourceCode r"><code class="sourceCode r">post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> diff)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>,
               <span class="dt">fill =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="dv">2</span>,
             <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;lambda_high - lambda_low&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-62-1.png" width="288" /></p>
<p>I’m not happy with how clunky this solution is, but one way to get those marginal dot and line plots for the axes is to make intermediary tibbles. Anyway, here’s a version of Figure 10.8.b.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># intermediary tibbles for our the dot and line portoin of the plot</span>
point_tibble &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="kw">median</span>(post<span class="op">$</span>b_contact_high), <span class="kw">min</span>(post<span class="op">$</span>b_contact_high)),
         
         <span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">min</span>(post<span class="op">$</span><span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>), <span class="kw">median</span>(post<span class="op">$</span><span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>)))

line_tibble &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">parameter =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;b_contact_high&quot;</span>, <span class="st">&quot;b_log_pop:contact_high&quot;</span>), <span class="dt">each =</span> <span class="dv">2</span>),
         
         <span class="dt">x =</span> <span class="kw">c</span>(<span class="kw">quantile</span>(post<span class="op">$</span>b_contact_high, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>)),
               <span class="kw">rep</span>(<span class="kw">min</span>(post<span class="op">$</span>b_contact_high), <span class="dt">times =</span> <span class="dv">2</span>)),
         
         <span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="kw">min</span>(post<span class="op">$</span><span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>), <span class="dt">times =</span> <span class="dv">2</span>),
               <span class="kw">quantile</span>(post<span class="op">$</span><span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>))))

<span class="co"># the plot</span>
post <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> b_contact_high, <span class="dt">y =</span> <span class="st">`</span><span class="dt">b_log_pop:contact_high</span><span class="st">`</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>],
             <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> point_tibble,
             <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> line_tibble,
            <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">group =</span> parameter))</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-63-1.png" width="288" /></p>
<p>Here we deconstruct model <code>b10.10</code>, bit by bit.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># no interaction</span>
b10<span class="fl">.11</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">update</span>(b10<span class="fl">.10</span>, <span class="dt">formula =</span> total_tools <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>log_pop <span class="op">+</span><span class="st"> </span>contact_high)

<span class="co"># no contact rate</span>
b10<span class="fl">.12</span> &lt;-
<span class="st">  </span><span class="kw">update</span>(b10<span class="fl">.10</span>, <span class="dt">formula =</span> total_tools <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>log_pop)

<span class="co"># no log-population</span>
b10<span class="fl">.13</span> &lt;-
<span class="st">  </span><span class="kw">update</span>(b10<span class="fl">.10</span>, <span class="dt">formula =</span> total_tools <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>contact_high)

<span class="co"># intercept only</span>
b10<span class="fl">.14</span> &lt;-
<span class="st">  </span><span class="kw">update</span>(b10<span class="fl">.10</span>, <span class="dt">formula =</span> total_tools <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
         <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>I know we got all excited with the LOO, above. Let’s just be lazy and go WAIC. [Though beware, the LOO opens up a similar can of worms, here.]</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.10</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.10</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.11</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.11</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.12</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.12</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.13</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.13</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)
b10<span class="fl">.14</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b10<span class="fl">.14</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)</code></pre>
<p>Now compare them.</p>
<pre class="sourceCode r"><code class="sourceCode r">w &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(b10<span class="fl">.10</span>, b10<span class="fl">.11</span>, b10<span class="fl">.12</span>, b10<span class="fl">.13</span>, b10<span class="fl">.14</span>, <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)

<span class="kw">cbind</span>(<span class="dt">waic_diff =</span> w[, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="dv">-2</span>,
      <span class="dt">se        =</span> w[, <span class="dv">2</span>] <span class="op">*</span><span class="st">  </span><span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##        waic_diff    se
## b10.11      0.00  0.00
## b10.10      0.65  1.23
## b10.12      5.09  8.43
## b10.14     62.13 34.54
## b10.13     70.77 46.41</code></pre>
<p>Let’s get those WAIC weights, too.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model_weights</span>(b10<span class="fl">.10</span>, b10<span class="fl">.11</span>, b10<span class="fl">.12</span>, b10<span class="fl">.13</span>, b10<span class="fl">.14</span>, <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## b10.10 b10.11 b10.12 b10.13 b10.14 
##   0.40   0.55   0.04   0.00   0.00</code></pre>
<p>Now wrangle <code>w</code> a little and make the WAIC plot.</p>
<pre class="sourceCode r"><code class="sourceCode r">w <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="dt">var =</span> <span class="st">&quot;model&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">reorder</span>(model, <span class="op">-</span>waic), 
             <span class="dt">y    =</span> waic,
             <span class="dt">ymin =</span> waic <span class="op">-</span><span class="st"> </span>se_waic,
             <span class="dt">ymax =</span> waic <span class="op">+</span><span class="st"> </span>se_waic,
             <span class="dt">color =</span> model)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">16</span>, <span class="dt">show.legend =</span> F) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)]) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>,
       <span class="dt">title =</span> <span class="st">&quot;WAIC&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y    =</span> <span class="kw">element_blank</span>())</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-66-1.png" width="432" /></p>
<p>Here’s our version of Figure 10.9. Recall, to do an “ensemble” posterior prediction in brms, one uses the <code>pp_average()</code> function. I know we were just lazy and focused on the WAIC. But let’s play around, a bit. Here we’ll weight the models based on the LOO by adding a <code>weights = &quot;loo&quot;</code> argument to the <code>pp_average()</code> function. If you check the corresponding section of the <a href="https://cran.r-project.org/web/packages/brms/brms.pdf">brms reference manual</a>, you’ll find several weighting schemes.</p>
<pre class="sourceCode r"><code class="sourceCode r">nd &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">contact_high =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">expand</span>(contact_high,
         <span class="dt">log_pop =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">6.5</span>, <span class="dt">to =</span> <span class="dv">13</span>, <span class="dt">length.out =</span> <span class="dv">50</span>))

ppa &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">pp_average</span>(b10<span class="fl">.10</span>, b10<span class="fl">.11</span>, b10<span class="fl">.12</span>,
             <span class="dt">weights =</span> <span class="st">&quot;loo&quot;</span>,
             <span class="dt">method  =</span> <span class="st">&quot;fitted&quot;</span>,
             <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

ppa <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x     =</span> log_pop,
             <span class="dt">group =</span> contact_high)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>,
                  <span class="dt">fill =</span> contact_high, <span class="dt">color =</span> contact_high),
              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,
              <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> d, 
             <span class="kw">aes</span>(<span class="dt">y     =</span> total_tools,
                 <span class="dt">label =</span> total_tools,
                 <span class="dt">color =</span> contact_high),
             <span class="dt">size =</span> <span class="fl">3.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="fl">7.1</span>, <span class="fl">12.4</span>),
                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">12</span>, <span class="dv">70</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log population&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;total tools&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Blue is the high contact rate; black is the low.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">panel.border    =</span> <span class="kw">element_blank</span>())</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-67-1.png" width="336" /></p>
<p>In case you were curious, here are those LOO weights:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model_weights</span>(b10<span class="fl">.10</span>, b10<span class="fl">.11</span>, b10<span class="fl">.12</span>, 
              <span class="dt">weights =</span> <span class="st">&quot;loo&quot;</span>)</code></pre>
<pre><code>##     b10.10     b10.11     b10.12 
## 0.35654696 0.60198589 0.04146715</code></pre>
</div>
<div id="mcmc-islands." class="section level3">
<h3><span class="header-section-number">10.2.2</span> MCMC islands.</h3>
<p>We fit our analogue to <code>m10.10stan</code>, <code>b10.10</code>, some time ago.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.10</span>)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: total_tools ~ 1 + log_pop + contact_high + contact_high:log_pop 
##    Data: d (Number of observations: 10) 
## Samples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##                      Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept                0.94      0.37     0.20     1.64       4075 1.00
## log_pop                  0.26      0.04     0.19     0.33       4317 1.00
## contact_high            -0.09      0.82    -1.70     1.49       2406 1.00
## log_pop:contact_high     0.04      0.09    -0.13     0.22       2397 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Center <code>log_pop</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_pop_c =</span> log_pop <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(log_pop))</code></pre>
<p>Now fit the <code>log_pop</code>-centered model.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.10</span>_c &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> poisson,
      total_tools <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>log_pop_c <span class="op">+</span><span class="st"> </span>contact_high <span class="op">+</span><span class="st"> </span>contact_high<span class="op">:</span>log_pop_c,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.10</span>_c)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: total_tools ~ 1 + log_pop_c + contact_high + contact_high:log_pop_c 
##    Data: d (Number of observations: 10) 
## Samples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##                        Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept                  3.31      0.09     3.14     3.48       6029 1.00
## log_pop_c                  0.26      0.03     0.19     0.33       6174 1.00
## contact_high               0.28      0.12     0.05     0.51       6622 1.00
## log_pop_c:contact_high     0.07      0.17    -0.26     0.39       7179 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We’ll use <code>mcmc_pairs()</code>, again, for Figure 10.10.a.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># this helps us set our custom color scheme</span>
<span class="kw">color_scheme_set</span>(<span class="kw">c</span>(<span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">3</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>], 
                   <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>]))

<span class="co"># the actual plot</span>
<span class="kw">mcmc_pairs</span>(<span class="dt">x =</span> <span class="kw">posterior_samples</span>(b10<span class="fl">.10</span>),
           <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>, <span class="st">&quot;b_log_pop&quot;</span>, <span class="st">&quot;b_contact_high&quot;</span>, <span class="st">&quot;b_log_pop:contact_high&quot;</span>),
           <span class="dt">off_diag_args =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>),
           <span class="dt">diag_fun =</span> <span class="st">&quot;dens&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-71-1.png" width="360" /></p>
<p>And now behold Figure 10.10.b.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_pairs</span>(<span class="dt">x =</span> <span class="kw">posterior_samples</span>(b10<span class="fl">.10</span>_c),
           <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b_Intercept&quot;</span>, <span class="st">&quot;b_log_pop_c&quot;</span>, <span class="st">&quot;b_contact_high&quot;</span>, <span class="st">&quot;b_log_pop_c:contact_high&quot;</span>),
           <span class="dt">off_diag_args =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>),
           <span class="dt">diag_fun =</span> <span class="st">&quot;dens&quot;</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-72-1.png" width="360" /></p>
<p>If you really want the correlation point estimates, use <code>psych::lowerCorr()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">psych<span class="op">::</span><span class="kw">lowerCor</span>(<span class="kw">posterior_samples</span>(b10<span class="fl">.10</span>)[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>])</code></pre>
<pre><code>##                        b_Int b_lg_ b_cn_ b__:_
## b_Intercept             1.00                  
## b_log_pop              -0.98  1.00            
## b_contact_high         -0.16  0.16  1.00      
## b_log_pop:contact_high  0.10 -0.12 -0.99  1.00</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">psych<span class="op">::</span><span class="kw">lowerCor</span>(<span class="kw">posterior_samples</span>(b10<span class="fl">.10</span>_c)[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>])</code></pre>
<pre><code>##                          b_Int b_l__ b_cn_ b___:
## b_Intercept               1.00                  
## b_log_pop_c              -0.45  1.00            
## b_contact_high           -0.76  0.33  1.00      
## b_log_pop_c:contact_high  0.11 -0.20 -0.27  1.00</code></pre>
</div>
<div id="example-exposure-and-the-offset." class="section level3">
<h3><span class="header-section-number">10.2.3</span> Example: Exposure and the offset.</h3>
<blockquote>
<p>For the last Poisson example, we’ll look at a case where the exposure varies across observations. When the length of observation, area of sampling, or intensity of sampling varies, the counts we observe also naturally vary. Since a Poisson distribution assumes that the rate of events is constant in time (or space), it’s easy to handle this. All we need to do, as explained on page 312 [of the text], is to add the logarithm of the exposure to the linear model. The term we add is typically called an <em>offset</em>. (p. 321, <em>emphasis</em> in the original)</p>
</blockquote>
<p>Here we simulate our data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">10</span>)

num_days  &lt;-<span class="st"> </span><span class="dv">30</span>
y         &lt;-<span class="st"> </span><span class="kw">rpois</span>(num_days, <span class="fl">1.5</span>)

num_weeks &lt;-<span class="st"> </span><span class="dv">4</span>
y_new     &lt;-<span class="st"> </span><span class="kw">rpois</span>(num_weeks, <span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span><span class="dv">7</span>)</code></pre>
<p>Let’s make them tidy and add <code>log_days</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">(
  d &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">y         =</span> <span class="kw">c</span>(y, y_new), 
         <span class="dt">days      =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, num_days), <span class="kw">rep</span>(<span class="dv">7</span>, num_weeks)),
         <span class="dt">monastery =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, num_days), <span class="kw">rep</span>(<span class="dv">1</span>, num_weeks))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_days  =</span> <span class="kw">log</span>(days))
)</code></pre>
<pre><code>## # A tibble: 34 x 4
##        y  days monastery log_days
##    &lt;int&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1     1     1         0        0
##  2     1     1         0        0
##  3     1     1         0        0
##  4     2     1         0        0
##  5     0     1         0        0
##  6     1     1         0        0
##  7     1     1         0        0
##  8     1     1         0        0
##  9     2     1         0        0
## 10     1     1         0        0
## # … with 24 more rows</code></pre>
<p>With the brms package, you use the <code>offset()</code> syntax, in which you put a pre-processed variable like <code>log_days</code> or the log of a variable, such as <code>log(days)</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.15</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> poisson,
      y <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(log_days) <span class="op">+</span><span class="st"> </span>monastery,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>The model summary:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.15</span>)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: y ~ 1 + offset(log_days) + monastery 
##    Data: d (Number of observations: 34) 
## Samples: 2 chains, each with iter = 2500; warmup = 500; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     0.30      0.16    -0.01     0.59       3083 1.00
## monastery    -1.10      0.31    -1.72    -0.50       3179 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The model summary helps clarify that when you use <code>offset()</code>, <code>brm()</code> fixes the value. Thus there is no parameter estimate for the <code>offset()</code>. It’s a fixed part of the model not unlike the <span class="math inline">\(\nu\)</span> parameter of the Student-<span class="math inline">\(t\)</span> distribution gets fixed to infinity when you use the Gaussian likelihood.</p>
<p>Here we’ll compute the posterior means and 89% HDIs with <code>tidybayes::mean_hdi()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidybayes)

<span class="kw">posterior_samples</span>(b10<span class="fl">.15</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">lambda_old =</span> <span class="kw">exp</span>(b_Intercept),
            <span class="dt">lambda_new =</span> <span class="kw">exp</span>(b_Intercept <span class="op">+</span><span class="st"> </span>b_monastery)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lambda_old&quot;</span>, <span class="st">&quot;lambda_new&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mean_hdi</span>(value, <span class="dt">.width =</span> <span class="fl">.89</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.double, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## # A tibble: 2 x 7
##   key        value .lower .upper .width .point .interval
##   &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 lambda_old  1.37   1.02   1.7    0.89 mean   hdi      
## 2 lambda_new  0.47   0.25   0.65   0.89 mean   hdi</code></pre>
<p>As McElreath pointed out in the text, “Your estimates will be slightly different, because you got different randomly simulated data” (p. 322).</p>
</div>
</div>
<div id="other-count-regressions" class="section level2">
<h2><span class="header-section-number">10.3</span> Other count regressions</h2>
<p>The next two of the remaining four models are maximum entropy distributions for certain problem types. The last two are mixtures, of which we’ll see more in the next chapter.</p>
<div id="multinomial." class="section level3">
<h3><span class="header-section-number">10.3.1</span> Multinomial.</h3>
<blockquote>
<p>When more than two types of unordered events are possible, and the probability of each type of event is constant across trials, then the maximum entropy distribution is the multinomial distribution. [We] already met the multinomial, implicitly, in Chapter 9 when we tossed pebbles into buckets as an introduction to maximum entropy. The binomial is really a special case of this distribution. And so its distribution formula resembles the binomial, just extrapolated out to three or more types of events. If there are <span class="math inline">\(K\)</span> types of events with probabilities <span class="math inline">\(p_1, …, p_K\)</span>, then the probability of observing <span class="math inline">\(y_1, …, y_K\)</span> events of each type out of <span class="math inline">\(n\)</span> trials is (p. 323):</p>
</blockquote>
<p><span class="math display">\[\text{Pr} (y_1, ..., y_K | n, p_1, ..., p_K) = \frac{n!}{\prod_i y_i!} \prod_{i = 1}^K p_i^{y_i}\]</span></p>
<p>Compare that equation with the simpler version in section 2.3.1 (page 33 in the text).</p>
<div id="explicit-multinomial-models." class="section level4">
<h4><span class="header-section-number">10.3.1.1</span> Explicit multinomial models.</h4>
<p>“The conventional and natural link is this context is the <em>multinomial logit</em>. This link function takes a vector of <em>scores</em>, one for each <span class="math inline">\(K\)</span> event types, and computed the probability of a particular type of event <span class="math inline">\(K\)</span> as” (p. 323, <em>emphasis</em> in the original)</p>
<p><span class="math display">\[\text{Pr} (k |s_1, s_2, ..., s_K) = \frac{\text{exp} (s_k)}{\sum_{i = 1}^K \text{exp} (s_i)}\]</span></p>
<p>Let’s simulate the data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)

<span class="co"># simulate career choices among 500 individuals</span>
n      &lt;-<span class="st"> </span><span class="dv">500</span>           <span class="co"># number of individuals</span>
income &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>           <span class="co"># expected income of each career</span>
score  &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>income  <span class="co"># scores for each career, based on income</span>

<span class="co"># next line converts scores to probabilities</span>
p &lt;-<span class="st"> </span><span class="kw">softmax</span>(score[<span class="dv">1</span>], score[<span class="dv">2</span>], score[<span class="dv">3</span>])

<span class="co"># now simulate choice</span>
<span class="co"># outcome career holds event type values, not counts</span>
career &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n)  <span class="co"># empty vector of choices for each individual</span>

<span class="kw">set.seed</span>(<span class="dv">10</span>)
<span class="co"># sample chosen career for each individual</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) career[i] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> p)</code></pre>
<p>Here’s what the data look like.</p>
<pre class="sourceCode r"><code class="sourceCode r">career <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>())) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>])</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-79-1.png" width="288" /></p>
<p>Switch out rethinking for brms.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre>
<p>Here’s my naïve attempt to fit the model in brms.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.16</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">career =</span> career), 
      <span class="dt">family =</span> <span class="kw">categorical</span>(<span class="dt">link =</span> logit),
      career <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> Intercept),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>This differs from McElreath’s <code>m10.16</code>. Most obviously, this has two parameters. McElreath’s <code>m10.16</code> only has one. If you have experience with these models and know how to reproduce McElreath’s results in brms, <a href="https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/issues/5">please share your code</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.16</span>)</code></pre>
<pre><code>##  Family: categorical 
##   Links: mu2 = logit; mu3 = logit 
## Formula: career ~ 1 
##    Data: list(career = career) (Number of observations: 500) 
## Samples: 2 chains, each with iter = 2500; warmup = 500; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## mu2_Intercept     0.49      0.13     0.23     0.76       1171 1.00
## mu3_Intercept     1.01      0.12     0.77     1.25       1241 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here’s the second data simulation, this time based on McElreath’s R code 10.58.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)

n &lt;-<span class="st"> </span><span class="dv">100</span>

<span class="kw">set.seed</span>(<span class="dv">10</span>)
<span class="co"># simulate family incomes for each individual</span>
family_income &lt;-<span class="st"> </span><span class="kw">runif</span>(n)

<span class="co"># assign a unique coefficient for each type of event</span>
b      &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">:-</span><span class="dv">1</span>)
career &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n)  <span class="co"># empty vector of choices for each individual</span>

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
    score     &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span>b <span class="op">*</span><span class="st"> </span>family_income[i]
    p         &lt;-<span class="st"> </span><span class="kw">softmax</span>(score[<span class="dv">1</span>], score[<span class="dv">2</span>], score[<span class="dv">3</span>])
    career[i] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> p)
}</code></pre>
<p>Switch out rethinking for brms.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre>
<p>Here’s the brms version of McElreath’s <code>m10.17</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.17</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">career        =</span> career,  <span class="co"># note how we used a list instead of a tibble</span>
                  <span class="dt">family_income =</span> family_income), 
      <span class="dt">family =</span> <span class="kw">categorical</span>(<span class="dt">link =</span> logit),
      career <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>family_income,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>Happily, these results cohere with the rethinking model.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.17</span>)</code></pre>
<pre><code>##  Family: categorical 
##   Links: mu2 = logit; mu3 = logit 
## Formula: career ~ 1 + family_income 
##    Data: list(career = career, family_income = family_incom (Number of observations: 100) 
## Samples: 2 chains, each with iter = 2500; warmup = 500; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                   Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## mu2_Intercept         1.04      0.54    -0.02     2.14       2530 1.00
## mu3_Intercept         1.04      0.56    -0.06     2.16       2425 1.00
## mu2_family_income    -1.81      1.00    -3.87     0.12       2528 1.00
## mu3_family_income    -1.75      1.03    -3.78     0.22       2566 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>McElreath described the parameters as “on a scale that is very hard to interpret” (p. 325). Indeed.</p>
</div>
<div id="multinomial-in-disguise-as-poisson." class="section level4">
<h4><span class="header-section-number">10.3.1.2</span> Multinomial in disguise as Poisson.</h4>
<p>Here we fit a multinomial likelihood by refactoring it to a series of Poissons. Let’s retrieve the Berkeley data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)

<span class="kw">data</span>(UCBadmit)
d &lt;-<span class="st"> </span>UCBadmit
<span class="kw">rm</span>(UCBadmit)

<span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre>
<p>Fit the models.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># binomial model of overall admission probability</span>
b_binom &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      admit <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(applications) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">3</span>, <span class="dt">chains =</span> <span class="dv">3</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)

<span class="co"># Poisson model of overall admission rate and rejection rate</span>
b_pois &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">rej =</span> reject),  <span class="co"># &#39;reject&#39; is a reserved word</span>
      <span class="dt">family =</span> poisson,
      <span class="kw">mvbind</span>(admit, rej) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">3</span>, <span class="dt">chains =</span> <span class="dv">3</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>Note, the <code>mvbind()</code> syntax made <code>b_pois</code> a multivariate Poisson model. Starting with version 2.0.0, <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html">brms supports a variety of multivariate models</a>. Anyway, here are the implications of <code>b_pois</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># extract the samples</span>
post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b_pois)

<span class="co"># wrangle</span>
post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">admit  =</span> <span class="kw">exp</span>(b_admit_Intercept), 
            <span class="dt">reject =</span> <span class="kw">exp</span>(b_rej_Intercept)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># plot</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">y =</span> key, <span class="dt">fill =</span> key)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">point_interval =</span> median_qi, <span class="dt">.width =</span> <span class="fl">.95</span>,
                <span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">4</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>],
                               <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">2</span>])) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot; Mean admit/reject rates across departments&quot;</span>,
       <span class="dt">x     =</span> <span class="st">&quot;# applications&quot;</span>,
       <span class="dt">y     =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">axis.ticks.y    =</span> <span class="kw">element_blank</span>())</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-86-1.png" width="624" /></p>
<p>The model summaries:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b_binom)</code></pre>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: admit | trials(applications) ~ 1 
##    Data: d (Number of observations: 12) 
## Samples: 3 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 3000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept    -0.46      0.03    -0.52    -0.40       1057 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b_pois)</code></pre>
<pre><code>##  Family: MV(poisson, poisson) 
##   Links: mu = log
##          mu = log 
## Formula: admit ~ 1 
##          rej ~ 1 
##    Data: d %&gt;% mutate(rej = reject) (Number of observations: 12) 
## Samples: 3 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 3000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## admit_Intercept     4.99      0.02     4.94     5.03       2002 1.00
## rej_Intercept       5.44      0.02     5.41     5.48       2346 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Here’s the posterior mean for the probability of admission, based on <code>b_binom</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fixef</span>(b_binom)[ ,<span class="st">&quot;Estimate&quot;</span>] <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inv_logit_scaled</span>()</code></pre>
<pre><code>## [1] 0.3875688</code></pre>
<p>Happily, we get the same value within simulation error from model <code>b_pois</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">fixef</span>(b_pois) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.numeric</span>()

<span class="kw">exp</span>(k[<span class="dv">1</span>]) <span class="op">/</span><span class="st"> </span>(<span class="kw">exp</span>(k[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(k[<span class="dv">2</span>]))</code></pre>
<pre><code>## [1] 0.387805</code></pre>
<p>The formula for what we just did in code is</p>
<p><span class="math display">\[p_{\text{admit}} = \frac{\lambda_1}{\lambda_1 + \lambda_2} = \frac{\text{exp} (\alpha_1)}{\text{exp} (\alpha_1) + \text{exp} (\alpha_2)}\]</span></p>
</div>
</div>
<div id="geometric." class="section level3">
<h3><span class="header-section-number">10.3.2</span> Geometric.</h3>
<blockquote>
<p>Sometimes a count variable is a number of events up until something happened. Call this “something” the terminating event. Often we want to model the probability of that event, a kind of analysis known as event history analysis or survival analysis. When the probability of the terminating event is constant through time (or distance), and the units of time (or distance) are discrete, a common likelihood function is the geometric distribution. This distribution has the form:</p>
<p><span class="math display">\[\text{Pr} (y | p) = p (1 - p) ^{y - 1}\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the number of time steps (events) until the terminating event occurred and <span class="math inline">\(p\)</span> is the probability of that event in each time step. This distribution has maximum entropy for unbounded counts with constant expected value. (pp. 327–328)</p>
</blockquote>
<p>Here we simulate exemplar data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate</span>
n &lt;-<span class="st"> </span><span class="dv">100</span>
<span class="kw">set.seed</span>(<span class="dv">10</span>)
x &lt;-<span class="st"> </span><span class="kw">runif</span>(n)

<span class="kw">set.seed</span>(<span class="dv">10</span>)
y &lt;-<span class="st"> </span><span class="kw">rgeom</span>(n, <span class="dt">prob =</span> <span class="kw">inv_logit_scaled</span>(<span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x))</code></pre>
<p>In case you’re curious, here are the data.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">list</span>(<span class="dt">y =</span> y, <span class="dt">x =</span> x) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-91-1.png" width="384" /></p>
<p>We fit the geometric model using <code>family = geometric(link = log)</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">b10<span class="fl">.18</span> &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> y, <span class="dt">x =</span> x), 
      <span class="dt">family =</span> <span class="kw">geometric</span>(<span class="dt">link =</span> log),
      y <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span>x,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b)),
      <span class="dt">iter =</span> <span class="dv">2500</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">cores =</span> <span class="dv">2</span>,
      <span class="dt">seed =</span> <span class="dv">10</span>)</code></pre>
<p>The results:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b10<span class="fl">.18</span>, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##  Family: geometric 
##   Links: mu = log 
## Formula: y ~ 0 + intercept + x 
##    Data: list(y = y, x = x) (Number of observations: 100) 
## Samples: 2 chains, each with iter = 2500; warmup = 500; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept     0.75      0.24     0.27     1.20       1248 1.00
## x            -1.63      0.51    -2.66    -0.63       1125 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>It turns out brms uses a <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_families.html#binary-and-count-data-models">different parameterization for the geometric distribution</a> than rethinking does. It follows the form</p>
<p><span class="math display">\[f(y_i) = {y_i \choose y_i} \bigg (\frac{\mu_i}{\mu_i + 1} \bigg )^{y_i} \bigg (\frac{1}{\mu_i + 1} \bigg )\]</span></p>
<p>Even though the parameters brms yielded look different from those in the text, their predictions describe the data well. Here’s the <code>marginal_effects()</code> plot:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">marginal_effects</span>(b10<span class="fl">.18</span>),
     <span class="dt">points =</span> T,
     <span class="dt">point_args =</span> <span class="kw">c</span>(<span class="dt">size =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>),
     <span class="dt">line_args  =</span> <span class="kw">c</span>(<span class="dt">color =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>],
                    <span class="dt">fill  =</span> <span class="kw">wes_palette</span>(<span class="st">&quot;Moonrise2&quot;</span>)[<span class="dv">1</span>]))</code></pre>
<p><img src="10_files/figure-html/unnamed-chunk-93-1.png" width="384" /></p>
</div>
</div>
<div id="reference-9" class="section level2 unnumbered">
<h2>Reference</h2>
<p><a href="https://xcelab.net/rm/statistical-rethinking/">McElreath, R. (2016). <em>Statistical rethinking: A Bayesian course with examples in R and Stan.</em> Chapman &amp; Hall/CRC Press.</a></p>
</div>
<div id="session-info-9" class="section level2 unnumbered">
<h2>Session info</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Debian GNU/Linux 10 (buster)
## 
## Matrix products: default
## BLAS/LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
##  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=C             
##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
## [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_1.1.0    loo_2.1.0          broom_0.5.2        bayesplot_1.7.0    ggthemes_4.2.0    
##  [6] wesanderson_0.3.6  forcats_0.4.0      stringr_1.4.0      dplyr_0.8.1        purrr_0.3.2       
## [11] readr_1.3.1        tidyr_0.8.3        tibble_2.1.3       tidyverse_1.2.1    brms_2.9.0        
## [16] Rcpp_1.0.1         dagitty_0.2-2      rstan_2.18.2       StanHeaders_2.18.1 ggplot2_3.1.1     
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1          ggridges_0.5.1            rsconnect_0.8.13          ggstance_0.3.1           
##   [5] markdown_1.0              base64enc_0.1-3           rstudioapi_0.10           listenv_0.7.0            
##   [9] farver_2.0.3              svUnit_0.7-12             DT_0.7                    fansi_0.4.0              
##  [13] mvtnorm_1.0-10            lubridate_1.7.4           xml2_1.2.0                bridgesampling_0.6-0     
##  [17] codetools_0.2-16          mnormt_1.5-5              knitr_1.23                shinythemes_1.1.2        
##  [21] zeallot_0.1.0             jsonlite_1.6              shiny_1.3.2               compiler_3.6.3           
##  [25] httr_1.4.0                backports_1.1.4           assertthat_0.2.1          Matrix_1.2-17            
##  [29] lazyeval_0.2.2            cli_1.1.0                 later_0.8.0               htmltools_0.3.6          
##  [33] prettyunits_1.0.2         tools_3.6.3               igraph_1.2.4.1            coda_0.19-2              
##  [37] gtable_0.3.0              glue_1.3.1                reshape2_1.4.3            V8_2.2                   
##  [41] cellranger_1.1.0          vctrs_0.1.0               nlme_3.1-144              crosstalk_1.0.0          
##  [45] psych_1.8.12              xfun_0.7                  globals_0.12.4            ps_1.3.0                 
##  [49] rvest_0.3.4               mime_0.7                  miniUI_0.1.1.1            lifecycle_0.1.0          
##  [53] gtools_3.8.1              future_1.13.0             MASS_7.3-51.5             zoo_1.8-6                
##  [57] scales_1.1.1.9000         colourpicker_1.0          hms_0.4.2                 promises_1.0.1           
##  [61] Brobdingnag_1.2-6         inline_0.3.15             shinystan_2.5.0           yaml_2.2.0               
##  [65] curl_3.3                  gridExtra_2.3             stringi_1.4.3             dygraphs_1.1.1.6         
##  [69] boot_1.3-24               pkgbuild_1.0.3            shape_1.4.4               rlang_0.4.0              
##  [73] pkgconfig_2.0.2           matrixStats_0.54.0        HDInterval_0.2.0          evaluate_0.14            
##  [77] lattice_0.20-38           labeling_0.3              rstantools_1.5.1          htmlwidgets_1.3          
##  [81] processx_3.3.1            tidyselect_0.2.5          plyr_1.8.4                magrittr_1.5             
##  [85] bookdown_0.11             R6_2.4.0                  generics_0.0.2            foreign_0.8-75           
##  [89] pillar_1.4.1              haven_2.1.0               withr_2.1.2               xts_0.11-2               
##  [93] abind_1.4-5               modelr_0.1.4              crayon_1.3.4              arrayhelpers_1.0-20160527
##  [97] utf8_1.1.4                rmarkdown_1.13            grid_3.6.3                readxl_1.3.1             
## [101] callr_3.2.0               threejs_0.3.1             digest_0.6.19             xtable_1.8-4             
## [105] httpuv_1.5.1              stats4_3.6.3              munsell_0.5.0             shinyjs_1.0</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="big-entropy-and-the-generalized-linear-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="monsters-and-mixtures.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
